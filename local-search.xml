<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>启动</title>
    <link href="/2024/11/27/%E5%90%AF%E5%8A%A8/"/>
    <url>/2024/11/27/%E5%90%AF%E5%8A%A8/</url>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="诶呀，不太对呢！" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="df6753d40f1318b943bd84b5b85eb079c248e7573b9fe923e654ad336bf51f48">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">猜一猜？</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <categories>
      
      <category>6.s081</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lab1</title>
    <link href="/2024/11/27/pingpong%E6%9C%AA%E8%A7%A3%E4%B9%8B%E8%B0%9C/"/>
    <url>/2024/11/27/pingpong%E6%9C%AA%E8%A7%A3%E4%B9%8B%E8%B0%9C/</url>
    
    <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="诶呀，不太对呢！" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="e481671ed8cc6e887ed42ba18715a26b17304bbb636d9c141adbc8d72b35e80c">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">猜一猜？</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
    
    
    <categories>
      
      <category>6.s081</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Llama_factory部署踩坑之旅</title>
    <link href="/2024/11/27/Llama-factory%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E4%B9%8B%E6%97%85/"/>
    <url>/2024/11/27/Llama-factory%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E4%B9%8B%E6%97%85/</url>
    
    <content type="html"><![CDATA[<p>记录一个很巧的报错，说来也巧，2024.11.18和同门在新机器上部署代码跑模型，早上在我工位电脑远程成功跑起模型，由于工作需要先在我电脑终止，下午在同门笔记本远程连接后同样的conda环境和路径命令跑不了了。重新创建conda环境拉取代码后一直报一个typo模块缺失的错，手动安装并永久添加到系统环境也无法解决，但是在吃饭的两个小时时间段有人提了一模一样的issue,第一反应是问同门是否是他提的</p><h2 id="No-module-named-‘tyro’"><a href="#No-module-named-‘tyro’" class="headerlink" title="No module named ‘tyro’"></a>No module named ‘tyro’</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ruby">(llama_factory) liujiayao_20240823_91<span class="hljs-variable">@dase314cxl</span><span class="hljs-symbol">:~/LLaMA-Factory-main</span><span class="hljs-variable">$ </span>python -c <span class="hljs-string">&quot;import tyro; print(tyro.__version__)&quot;</span><br><span class="hljs-title class_">Traceback</span> (most recent call last):<br>  <span class="hljs-title class_">File</span> <span class="hljs-string">&quot;&lt;string&gt;&quot;</span>, line <span class="hljs-number">1</span>, <span class="hljs-keyword">in</span> &lt;<span class="hljs-keyword">module</span>&gt;<br><span class="hljs-title class_">ModuleNotFoundError</span>: <span class="hljs-title class_">No</span> <span class="hljs-keyword">module</span> named <span class="hljs-string">&#x27;tyro&#x27;</span><br></code></pre></td></tr></table></figure><p>解决：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install tyro==<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.<span class="hljs-number">14</span><br></code></pre></td></tr></table></figure><p><a href="uri"></a><a href="https://github.com/hiyouga/LLaMA-Factory/issues/6060">https://github.com/hiyouga/LLaMA-Factory/issues/6060</a></p><h2 id="version-GLIBCXX-3-4-32’-not-found"><a href="#version-GLIBCXX-3-4-32’-not-found" class="headerlink" title="version GLIBCXX_3.4.32’ not found"></a>version GLIBCXX_3.4.32’ not found</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">[rank0]: ImportError: <span class="hljs-regexp">/home/</span>liujiayao_20240823_91<span class="hljs-regexp">/miniconda3/</span>envs<span class="hljs-regexp">/llama_factory/</span>bin<span class="hljs-regexp">/../</span>lib<span class="hljs-regexp">/libstdc++.so.6: version GLIBCXX_3.4.32&#x27; not found (required by /</span>home<span class="hljs-regexp">/liujiayao_20240823_91/</span>.cache<span class="hljs-regexp">/torch_extensions/</span>py310_cu124<span class="hljs-regexp">/cpu_adam/</span>cpu_adam.so)<br></code></pre></td></tr></table></figure><p>解决方案很多，因不想降低scipy的版最终通过在对应conda环境通过 conda install -c conda-forge gcc 来解决。<br><a href="uri"></a><a href="https://zhuanlan.zhihu.com/p/637165718?utm_medium=social&utm_psn=1842275695461552129&utm_source=wechat_session">https://zhuanlan.zhihu.com/p/637165718?utm_medium=social&amp;utm_psn=1842275695461552129&amp;utm_source=wechat_session</a><br>可能有用的教程：<br><a href="uri"></a><a href="https://stackoverflow.com/questions/76974555/glibcxx-3-4-32-not-found-error-at-runtime-gcc-13-2-0">https://stackoverflow.com/questions/76974555/glibcxx-3-4-32-not-found-error-at-runtime-gcc-13-2-0</a><br><a href="uri"></a><a href="https://zhuanlan.zhihu.com/p/685165815">https://zhuanlan.zhihu.com/p/685165815</a><br><a href="uri"></a><a href="https://zhuanlan.zhihu.com/p/142718039">https://zhuanlan.zhihu.com/p/142718039</a></p><h3 id="pip速度太慢"><a href="#pip速度太慢" class="headerlink" title="pip速度太慢"></a>pip速度太慢</h3><p>临时使用清华镜像</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">pip install 包名 -<span class="hljs-selector-tag">i</span> https:<span class="hljs-comment">//pypi.tuna.tsinghua.edu.cn/simple</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Llama_factory</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>deepspeed/runtime/engine.py</title>
    <link href="/2024/11/27/deepspeed-runtime-engine-py/"/>
    <url>/2024/11/27/deepspeed-runtime-engine-py/</url>
    
    <content type="html"><![CDATA[<h2 id="确定检查点保存的配置"><a href="#确定检查点保存的配置" class="headerlink" title="确定检查点保存的配置"></a>确定检查点保存的配置</h2><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lasso">def _save_checkpoint(<span class="hljs-built_in">self</span>, save_dir, <span class="hljs-built_in">tag</span>, client_state=&#123;&#125;, exclude_frozen_parameters=<span class="hljs-literal">False</span>):<br><br>       save_path = <span class="hljs-built_in">self</span>._get_ckpt_name(save_dir, <span class="hljs-built_in">tag</span>)<br><br>       zero_optimizer_state = <span class="hljs-built_in">self</span>.zero_optimization() <span class="hljs-literal">or</span> <span class="hljs-built_in">self</span>.bfloat16_enabled()<br><br>       save_frozen_param = <span class="hljs-built_in">self</span>.zero_optimization_partition_gradients() <span class="hljs-literal">and</span> <span class="hljs-literal">not</span> exclude_frozen_parameters<br><br></code></pre></td></tr></table></figure><ul><li>**save_path &#x3D; self._get_ckpt_name(save_dir, tag)**根据save_dir和tag生成完整的检查点保存路径。</li><li>**zero_optimizer_state &#x3D; self.zero_optimization() or self.bfloat16_enabled()**若启用 Zero Optimization 或 bfloat16，则需要保存优化器状态。</li><li><strong>save_frozen_param:</strong> 若启用 Zero Optimization 的梯度分区 且未排除冻结参数，则需要保存冻结参数。</li></ul><h2 id="收集模型的当前状态"><a href="#收集模型的当前状态" class="headerlink" title="收集模型的当前状态"></a>收集模型的当前状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>._curr_ckpt_path = os.path.join(save_dir, tag)<br>      module = <span class="hljs-variable language_">self</span>.module_state_dict(exclude_frozen_parameters=exclude_frozen_parameters)<br>      <span class="hljs-variable language_">self</span>._curr_ckpt_path = <span class="hljs-literal">None</span><br>      state = <span class="hljs-built_in">dict</span>(module=module,<br>                   buffer_names=<span class="hljs-variable language_">self</span>._get_buffer_names(),<br>                   optimizer=<span class="hljs-variable language_">self</span>.optimizer.state_dict() <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.optimizer <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> zero_optimizer_state <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   param_shapes=<span class="hljs-variable language_">self</span>._get_zero_param_shapes() <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.optimizer <span class="hljs-keyword">and</span> zero_optimizer_state <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   frozen_param_shapes=<span class="hljs-variable language_">self</span>._get_zero_frozen_param_attributes(<span class="hljs-variable language_">self</span>._get_param_shape_func)<br>                   <span class="hljs-keyword">if</span> save_frozen_param <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   shared_params=<span class="hljs-variable language_">self</span>._get_shared_params() <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.optimizer <span class="hljs-keyword">and</span> zero_optimizer_state <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   frozen_param_fragments=<span class="hljs-variable language_">self</span>._get_zero_frozen_param_attributes(<span class="hljs-variable language_">self</span>._get_param_fragment_func)<br>                   <span class="hljs-keyword">if</span> save_frozen_param <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   lr_scheduler=<span class="hljs-variable language_">self</span>.lr_scheduler.state_dict() <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.lr_scheduler <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   data_sampler=<span class="hljs-variable language_">self</span>.training_dataloader.data_sampler.state_dict() <span class="hljs-keyword">if</span><br>                   (<span class="hljs-variable language_">self</span>.training_dataloader <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-variable language_">self</span>.curriculum_learning_enabled()) <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   random_ltd=<span class="hljs-variable language_">self</span>.random_ltd_scheduler.state_dict() <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.random_ltd_enabled() <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                   sparse_tensor_module_names=<span class="hljs-variable language_">self</span>.sparse_tensor_module_names,<br>                   skipped_steps=<span class="hljs-variable language_">self</span>.skipped_steps,<br>                   global_steps=<span class="hljs-variable language_">self</span>.global_steps,<br>                   global_samples=<span class="hljs-variable language_">self</span>.global_samples,<br>                   dp_world_size=<span class="hljs-variable language_">self</span>.seq_dp_world_size,<br>                   mp_world_size=<span class="hljs-variable language_">self</span>.mp_world_size,<br>                   ds_config=<span class="hljs-variable language_">self</span>.config,<br>                   ds_version=version)<br>      state.update(client_state)<br></code></pre></td></tr></table></figure><p>在使用 Pipeline Parallelism（流水线并行） 的训练模式时，<br>默认行为被重写，导致直接调用 module_state_dict() 返回 None，因为在流水线并行训练模式下，各个模块可能并没有直接获取到完整的状态数据。在调用 module_state_dict() 之前，临时设置一个保存路径变量 self._curr_ckpt_path。<br>PipelineEngine 的 module_state_dict() 实现会检查 <strong>self._curr_ckpt_path</strong> 是否存在，并利用它作为保存路径。<br>在完成 module_state_dict() 的调用之后，将 self._curr_ckpt_path 重置为 None，以免影响其他模块的逻辑。</p><ul><li>**self._curr_ckpt_path &#x3D; os.path.join(save_dir, tag)**将检查点保存路径设置为 save_dir 和 tag 的组合路径。 这是为了解决流水线并行模式下 module_state_dict() 依赖 self._curr_ckpt_path 的问题，确保其能够正确返回模型状态字典。</li><li><strong>module &#x3D; self.module_state_dict</strong>(exclude_frozen_parameters&#x3D;exclude_frozen_parameters)调用 module_state_dict: 获取模型的状态字典。参数 exclude_frozen_parameters 用于指定是否排除冻结参数（例如固定不更新的权重）。</li><li><strong>self._curr_ckpt_path &#x3D; None</strong> 将 self._curr_ckpt_path 重置为 None，恢复初始状态。</li><li>**state &#x3D; dict()**构造一个字典 state，保存与模型和训练相关的各种状态信息：<br><strong>module</strong>: 模型的状态字典，由 module_state_dict 提供。<br>buffer_names: 模型中所有 buffer 的名称，调用 _get_buffer_names() 获取。<br><strong>optimizer</strong>: 优化器状态，通过 self.optimizer.state_dict() 提取。仅在启用了优化器且不使用 zero_optimizer_state 时保存。<br><strong>param_shapes</strong>: 参数形状。仅在启用 zero_optimizer_state 时保存，调用 _get_zero_param_shapes()。<br><strong>frozen_param_shapes</strong>: 冻结参数的形状。仅在启用 save_frozen_param 时保存，调用 _get_zero_frozen_param_attributes(self._get_param_shape_func)。<br><strong>shared_params</strong>: 共享参数信息，调用 _get_shared_params()。<br><strong>frozen_param_fragments</strong>: 冻结参数片段。类似于冻结参数形状，但数据片段级别，调用 _get_zero_frozen_param_attributes(self._get_param_fragment_func)。<br><strong>lr_scheduler</strong>: 学习率调度器状态字典，由 self.lr_scheduler.state_dict() 提供。<br><strong>data_sampler</strong>: 数据采样器状态字典。如果启用了课程学习（curriculum_learning_enabled()）并且有训练数据加载器，则调用 self.training_dataloader.data_sampler.state_dict()。<br><strong>random_ltd</strong>: 随机 LTD 调度器状态字典（用于随机剪枝或模型压缩），通过 <strong>self.random_ltd_scheduler.state_dict()</strong> 获取。<br><strong>sparse_tensor_module_names</strong>: 稀疏张量模块的名称。<br><strong>skipped_steps</strong>: 当前训练中跳过的步骤数。<br><strong>global_steps</strong>: 全局训练步数。<br><strong>global_samples</strong>: 全局训练样本数。<br><strong>dp_world_size</strong>: 数据并行的全局工作大小。<br><strong>mp_world_size</strong>: 模型并行的全局工作大小。<br><strong>ds_config</strong>: DeepSpeed 的配置。<br><strong>ds_version</strong>: DeepSpeed 的版本信息。</li><li>**state.update(client_state)**将外部传入的 client_state 添加到 state 字典中，扩展其内容。</li></ul><h2 id="处理冻结参数形状"><a href="#处理冻结参数形状" class="headerlink" title="处理冻结参数形状"></a>处理冻结参数形状</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">frozen_param_shapes = state<span class="hljs-selector-attr">[<span class="hljs-string">&#x27;frozen_param_shapes&#x27;</span>]</span><br>       frozen_param_shapes_str = <span class="hljs-built_in">str</span>(frozen_param_shapes)<br>       frozen_param_shapes_dict = &#123;key: <span class="hljs-built_in">list</span>(value) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, torch.Size) <span class="hljs-keyword">else</span> value<span class="hljs-selector-class">.tolist</span>() <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> frozen_param_shapes<span class="hljs-selector-class">.items</span>()&#125;<br><br></code></pre></td></tr></table></figure><ul><li><strong>frozen_param_shapes &#x3D; state[‘frozen_param_shapes’]</strong><br>**frozen_param_shapes_str &#x3D; str(frozen_param_shapes)**提取冻结参数的形状信息，并转换为字符串格式以便后续处理。</li><li><strong>frozen_param_shapes_dict</strong> &#x3D; {<br>  key: list(value) if isinstance(value, torch.Size) else value.tolist()<br>  for key, value in frozen_param_shapes.items()<br>}遍历字典中的每个键值对将 frozen_param_shapes 中的内容格式化为适合保存为 JSON 文件的形式。<br>如果是 <strong>torch.Size</strong>类型(torch.Size 是 PyTorch 中表示张量形状的类，但它是不可直接序列化为 JSON 的)调用 <strong>list(value)</strong> 将其转换为 Python 的列表（如 (3, 4) 转为 [3, 4]）,张量（torch.Tensor）也不可直接序列化为 JSON。调用 <strong>.tolist()</strong> 将张量内容转换为 Python 的列表。<br>例如，形如 torch.tensor([1, 2, 3]) 会转换为 [1, 2, 3]。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li><strong>确定检查点保存的配置</strong>：包括路径、状态和所需部分。<br>确定保存路径：使用 self._get_ckpt_name(save_dir, tag) 方法生成保存路径 save_path。<br>确定保存状态：zero_optimizer_state：是否保存优化器的非零状态（由 Zero Optimization 和 bfloat16 支持决定）。save_frozen_param：是否保存冻结参数状态（需要 Zero Optimization 的分区梯度功能并且没有排除冻结参数）。</li><li><strong>收集模型的当前状态</strong>：构建保存字典（state）<br>保存模块状态：通过设置 self._curr_ckpt_path，解决 Pipeline Parallelism 中 module_state_dict() 的路径依赖问题，获取模块状态。<br>构建状态字典 (**state)**：包含模型和训练相关的多种状态：<br>模型权重（module），优化器状态（optimizer），参数形状（param_shapes）<br>冻结参数形状及片段（frozen_param_shapes 和 frozen_param_fragments），学习率调度器状态（lr_scheduler），数据采样器状态（data_sampler）<br>随机梯度裁剪（random_ltd），其它全局状态（例如步数、样本数、配置等）</li><li><strong>处理冻结参数形状</strong>：将 frozen_param_shapes 转换为字典格式（从 torch.Size 转为列表）。</li><li><strong>完整保存检查点</strong>：用于模型后续的加载和恢复。</li></ul><h2 id="frozen-param-shapes"><a href="#frozen-param-shapes" class="headerlink" title="frozen_param_shapes"></a>frozen_param_shapes</h2><p><strong>目的</strong>:遍历模型的参数，检查哪些参数是冻结的（即不需要梯度更新的），并统计它们分布在 CPU 和 GPU 上的数量，同时通过给定的 attr_func 获取每个冻结参数的属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_get_zero_frozen_param_attributes</span>(<span class="hljs-params">self, attr_func</span>):<br>        frozen_param_fragments = OrderedDict()<br>        cpu = <span class="hljs-number">0</span><br>        gpu = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.module.parameters():<br>            <span class="hljs-keyword">if</span> param.requires_grad:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span> param <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.param_names:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;failed to find frozen <span class="hljs-subst">&#123;param&#125;</span> in named params&quot;</span>)<br>            name = <span class="hljs-variable language_">self</span>.param_names[param]<br>            <span class="hljs-comment">#pdb.set_trace()</span><br>            <br>            <span class="hljs-keyword">if</span> param.ds_tensor.device == torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>):<br>                cpu+=<span class="hljs-number">1</span><br>               <span class="hljs-comment"># print(f&quot;Device of param &#123;param&#125;: &#123;param.ds_tensor.device&#125;&quot;)</span><br>            <span class="hljs-keyword">else</span> :<br>                pdb.set_trace()<br>                gpu+=<span class="hljs-number">1</span><br>                <span class="hljs-comment">#print(param.ds_tensor.device)</span><br><br>            frozen_param_fragments[name] = attr_func(param)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;cpu次数: <span class="hljs-subst">&#123;cpu&#125;</span>&quot;</span>) <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;gpu次数: <span class="hljs-subst">&#123;gpu&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">return</span> frozen_param_fragments<br></code></pre></td></tr></table></figure><ul><li><strong>frozen_param_fragments</strong>：存储冻结参数及其通过 attr_func 提取的属性，使用 OrderedDict 按插入顺序存储键值对。</li><li><strong>for param in self.module.parameters()</strong>:遍历模型中所有的参数。</li><li><strong>if param.requires_grad:continue</strong> 这里param.requires_grad&#x3D;True 表示该参数是可训练的，即需要进行梯度更新，因此跳过这些参数，只处理冻结的参数（requires_grad&#x3D;False）。</li><li><strong>if param not in self.param_names:</strong> param 必须在 self.param_names 中有对应的名称。如果没有找到，抛出一个 ValueError 错误，表示无法找到该参数的名称。</li><li><strong>name &#x3D; self.param_names[param]</strong>:获取冻结参数的名称，存储在 name 变量中。这个名称通常用于在 frozen_param_fragments 字典中标识每个参数。</li><li>if param.ds_tensor.device &#x3D;&#x3D; torch.device(‘cpu’):<br>  cpu +&#x3D; 1<br>else:<br>  gpu +&#x3D; 1区分 CPU 和 GPU 中的冻结参数，并分别统计它们的数量。</li><li>**frozen_param_fragments[name] &#x3D; attr_func(param)**：对每个冻结参数，调用 attr_func(param) 来获取其相关属性，并将该属性存储在 frozen_param_fragments 字典中。字典的键是参数的名称 name，值是通过 attr_func 获取的属性。</li></ul><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><ol><li><strong>初始化数据结构</strong>：创建存储冻结参数的字典 frozen_param_fragments 和设备计数器 cpu、gpu。</li><li><strong>遍历模型参数</strong>：遍历模型中所有的参数，筛选出冻结参数。检查参数名称：确保冻结参数在 self.param_names 中有对应的名称。</li><li><strong>统计设备信息</strong>：判断冻结参数所在的设备，并统计 CPU 和 GPU 上冻结参数的数量。提取属性：通过调用 attr_func 提取冻结参数的属性。</li><li><strong>打印统计信息</strong>：打印 CPU 和 GPU 上冻结参数的数量。</li><li><strong>返回结果</strong>：返回包含冻结参数名称和属性的字典。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Llama_factory</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pdb启动微调</title>
    <link href="/2024/11/27/pdb%E5%90%AF%E5%8A%A8%E5%BE%AE%E8%B0%83-1/"/>
    <url>/2024/11/27/pdb%E5%90%AF%E5%8A%A8%E5%BE%AE%E8%B0%83-1/</url>
    
    <content type="html"><![CDATA[<h2 id="245机器上启动pdb微调："><a href="#245机器上启动pdb微调：" class="headerlink" title="245机器上启动pdb微调："></a>245机器上启动pdb微调：</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">conda activate llama_factory<br>cd Downloads/LLaMA-Factory/<br><span class="hljs-built_in">export</span> <span class="hljs-attribute">FORCE_TORCHRUN</span>=1<br></code></pre></td></tr></table></figure><ul><li><strong>pdb：</strong></li></ul><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">CUDA_VISIBLE_DEVICES=1 python3 -m pdb $<span class="hljs-params">(which llamafactory-cli)</span> train     <span class="hljs-params">--stage</span> sft     <span class="hljs-params">--do_train</span>     <span class="hljs-params">--model_name_or_path</span> <span class="hljs-string">/home/dell/sdb/.cache/Qwen2-0___5B-Instruct</span>     <span class="hljs-params">--dataset</span> identity     <span class="hljs-params">--dataset_dir</span> <span class="hljs-string">./data</span>     <span class="hljs-params">--template</span> qwen     <span class="hljs-params">--finetuning_type</span> freeze     <span class="hljs-params">--output_dir</span> <span class="hljs-string">/home/dell/sdb/saves/Qwen2-0___5B-Instruct/freeze/sft</span>     <span class="hljs-params">--overwrite_cache</span>     <span class="hljs-params">--overwrite_output_dir</span>     <span class="hljs-params">--cutoff_len</span> 1024     <span class="hljs-params">--preprocessing_num_workers</span> 16     <span class="hljs-params">--per_device_train_batch_size</span> 2     <span class="hljs-params">--per_device_eval_batch_size</span> 1     <span class="hljs-params">--gradient_accumulation_steps</span> 8     <span class="hljs-params">--lr_scheduler_type</span> cosine     <span class="hljs-params">--logging_steps</span> 50     <span class="hljs-params">--warmup_steps</span> 20     <span class="hljs-params">--save_steps</span> 100     <span class="hljs-params">--eval_steps</span> 50     <span class="hljs-params">--evaluation_strategy</span> steps     <span class="hljs-params">--load_best_model_at_end</span>     <span class="hljs-params">--learning_rate</span> 5e-5     <span class="hljs-params">--num_train_epochs</span> 5.0     <span class="hljs-params">--max_samples</span> 1000     <span class="hljs-params">--val_size</span> 0.1     <span class="hljs-params">--plot_loss</span>     <span class="hljs-params">--fp16</span>     <span class="hljs-params">--deepspeed</span> examples/deepspeed/ds_z3_offload_config.json<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>检查点存储流程</title>
    <link href="/2024/11/27/%E6%A3%80%E6%9F%A5%E7%82%B9%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/"/>
    <url>/2024/11/27/%E6%A3%80%E6%9F%A5%E7%82%B9%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="保存checkpoint日志解析"><a href="#保存checkpoint日志解析" class="headerlink" title="保存checkpoint日志解析"></a>保存checkpoint日志解析</h1><ul><li><strong>保存检查点开始</strong><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">402</span> &gt;&gt; Saving model <span class="hljs-keyword">checkpoint</span> <span class="hljs-keyword">to</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span><br></code></pre></td></tr></table></figure>模型检查点将被保存到指定路径 &#x2F;home&#x2F;dell&#x2F;sdb&#x2F;saves&#x2F;Qwen2-0___5B-Instruct&#x2F;freeze&#x2F;sft&#x2F;checkpoint-25，代表训练中的第25次迭代或某个训练进度标志。</li><li>保存配置文件<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|configuration_utils.py:<span class="hljs-number">472</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">406</span> &gt;&gt; <span class="hljs-keyword">Configuration</span> saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/config.json<br>[<span class="hljs-keyword">INFO</span>|configuration_utils.py:<span class="hljs-number">807</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">406</span> &gt;&gt; <span class="hljs-keyword">Configuration</span> saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/generation_config.json<br></code></pre></td></tr></table></figure>config.json 和 generation_config.json 分别保存模型的基础配置和生成参数配置，确保模型加载时可以正确重现训练环境。</li><li>保存模型权重文件</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|modeling_utils.py:<span class="hljs-number">2766</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">213</span> &gt;&gt; Model weights saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/model.safetensors<br></code></pre></td></tr></table></figure><p>权重文件保存为 model.safetensors 格式。</p><ul><li>保存分词器文件</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|tokenization_utils_base.py:<span class="hljs-number">2702</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">214</span> &gt;&gt; tokenizer config file saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/tokenizer_config.json<br>[<span class="hljs-keyword">INFO</span>|tokenization_utils_base.py:<span class="hljs-number">2711</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">214</span> &gt;&gt; Special tokens file saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/special_tokens_map.json<br></code></pre></td></tr></table></figure><p>tokenizer_config.json：分词器的配置信息。<br>special_tokens_map.json：保存特殊 token（如 pad_token、cls_token 等）的映射关系。</p><h2 id="保存-DeepSpeed-检查点"><a href="#保存-DeepSpeed-检查点" class="headerlink" title="保存 DeepSpeed 检查点"></a>保存 DeepSpeed 检查点</h2><ul><li>记录全局步骤的检查点信息</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">20</span>:<span class="hljs-number">31</span>,<span class="hljs-number">627</span>] [<span class="hljs-keyword">INFO</span>] [logging.py:<span class="hljs-number">96</span>:log_dist] [Rank <span class="hljs-number">0</span>] [Torch] <span class="hljs-keyword">Checkpoint</span> global_step25 <span class="hljs-keyword">is</span> about <span class="hljs-keyword">to</span> be saved!<br><br></code></pre></td></tr></table></figure><p>global_step25 代表训练到第 25 个全局步骤的状态。</p><ul><li>保存零冗余优化器的检查点文件<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">22</span>:<span class="hljs-number">33</span>,<span class="hljs-number">574</span>] [<span class="hljs-keyword">INFO</span>] [logging.py:<span class="hljs-number">96</span>:log_dist] [Rank <span class="hljs-number">0</span>] Saving model <span class="hljs-keyword">checkpoint</span>: /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/global_step25/zero_pp_rank_0_mp_rank_00_model_states.pt<br></code></pre></td></tr></table></figure>zero_pp_rank_0_mp_rank_00_model_states.pt：保存当前模型状态，用于零冗余优化（ZeRO）的分布式训练。</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">22</span>:<span class="hljs-number">33</span>,<span class="hljs-number">575</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">21</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saving</span> ...<br>[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">26</span>:<span class="hljs-number">56</span>,<span class="hljs-number">161</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">23</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saved</span> ...<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">27</span>:<span class="hljs-number">11</span>,<span class="hljs-number">351</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">23</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saved</span> .../zero_pp_rank_0_mp_rank_00_optim_states.pt.<br></code></pre></td></tr></table></figure><p>zero_pp_rank_0_mp_rank_00_optim_states.pt 保存优化器状态，保证恢复训练时可以正确加载优化器的参数。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7"><span class="hljs-comment">[2024-11-21 10:27:11,369]</span> <span class="hljs-comment">[INFO]</span> <span class="hljs-comment">[engine.py:3589:_save_zero_checkpoint]</span> zero checkpoint saved ...<br><span class="hljs-comment">[2024-11-21 10:27:11,369]</span> <span class="hljs-comment">[INFO]</span> <span class="hljs-comment">[torch_checkpoint_engine.py:33:commit]</span> <span class="hljs-comment">[Torch]</span> Checkpoint global_step25 <span class="hljs-keyword">is</span> ready now!<br><br></code></pre></td></tr></table></figure><p>所有文件均保存完成，检查点 global_step25 可以正常使用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>DeepSpeed 和 PyTorch 结合使用，完整的检查点保存流程</strong>：</p><ol><li>模型参数（权重）</li><li>优化器状态</li><li>配置文件</li><li>特殊辅助文件（如冻结参数形状和分词器信息）</li></ol><h1 id="transformers-trainer-py"><a href="#transformers-trainer-py" class="headerlink" title="transformers&#x2F;trainer.py"></a>transformers&#x2F;trainer.py</h1><h2 id="核心逻辑"><a href="#核心逻辑" class="headerlink" title="核心逻辑"></a>核心逻辑</h2><p>在分布式训练中，多个进程通常会并行运行，为了避免重复保存检查点（例如由每个进程都保存一次），通常只有主进程（通常称为 rank 0 或“进程 0”）负责保存检查点。<br>如果该函数运行到了这一步，说明调用者已经确保此代码只会在进程 0 上执行。因此，无需在此处再次检查是否为主进程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_save</span>(<span class="hljs-params">self, output_dir: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>, state_dict=<span class="hljs-literal">None</span></span>):<br>       output_dir = output_dir <span class="hljs-keyword">if</span> output_dir <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-variable language_">self</span>.args.output_dir<br>       os.makedirs(output_dir, exist_ok=<span class="hljs-literal">True</span>)<br>       logger.info(<span class="hljs-string">f&quot;Saving model checkpoint to <span class="hljs-subst">&#123;output_dir&#125;</span>&quot;</span>)<br>       <span class="hljs-comment"># 确定支持的模型类型</span><br>       supported_classes = (PreTrainedModel,) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> is_peft_available() <span class="hljs-keyword">else</span> (PreTrainedModel, PeftModel)<br><br>       <span class="hljs-comment"># 模型不是支持的类型,state_dict：获取模型参数的状态字典，用于保存权重。</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-variable language_">self</span>.model, supported_classes):<br>           <span class="hljs-keyword">if</span> state_dict <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>               state_dict = <span class="hljs-variable language_">self</span>.model.state_dict()<br>       <span class="hljs-comment"># 如果通过 self.accelerator.unwrap_model 解包后的模型属于支持的类：调用 save_pretrained() 方法保存模型到 output_dir，并传入 state_dict 和 safe_serialization 参数。</span><br>           <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-variable language_">self</span>.accelerator.unwrap_model(<span class="hljs-variable language_">self</span>.model), supported_classes):<br>               <span class="hljs-variable language_">self</span>.accelerator.unwrap_model(<span class="hljs-variable language_">self</span>.model).save_pretrained(<br>                   output_dir, state_dict=state_dict, safe_serialization=<span class="hljs-variable language_">self</span>.args.save_safetensors<br>               )<br>            <span class="hljs-comment"># 如果解包后的模型仍然不属于支持的类：记录日志：只保存模型state_dict</span><br>           <span class="hljs-keyword">else</span>:<br>               logger.info(<span class="hljs-string">&quot;Trainer.model is not a `PreTrainedModel`, only saving its state dict.&quot;</span>)<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.args.save_safetensors:<br>                   safetensors.torch.save_file(<br>                       state_dict, os.path.join(output_dir, SAFE_WEIGHTS_NAME), metadata=&#123;<span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;pt&quot;</span>&#125;<br>                   )<br>               <span class="hljs-keyword">else</span>:<br>                   torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))<br>       <span class="hljs-comment"># 如果 self.model 类型属于支持的类，直接调用 save_pretrained() 保存模型，包括 state_dict 和 safe_serialization 参数。</span><br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-variable language_">self</span>.model.save_pretrained(<br>               output_dir, state_dict=state_dict, safe_serialization=<span class="hljs-variable language_">self</span>.args.save_safetensors<br>           )<br>       <span class="hljs-comment">#save_pretrained 是主函数，用于保存分词器的完整状态 </span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.tokenizer <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>           <span class="hljs-variable language_">self</span>.tokenizer.save_pretrained(output_dir)<br><br>       <span class="hljs-comment"># 训练参数</span><br>       torch.save(<span class="hljs-variable language_">self</span>.args, os.path.join(output_dir, TRAINING_ARGS_NAME))<br></code></pre></td></tr></table></figure><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><strong>这段代码的功能是保存训练过程中生成的检查点，包括</strong>：</p><ul><li>模型权重state_dict：获取模型参数的状态字典，用于保存权重。</li><li>模型及其配置保存到指定的目录：self.model.save_pretrained(只有主进程才会保存模型)</li><li>分词器配置：self.tokenizer.save_pretrained(output_dir)，用于保存模型的函数，默认为 torch.save</li><li>训练参数：torch.save</li></ul><h2 id="save-pretrained核心逻辑"><a href="#save-pretrained核心逻辑" class="headerlink" title="save_pretrained核心逻辑"></a>save_pretrained核心逻辑</h2><p><strong>save_pretrained</strong> 函数的核心逻辑是将训练好的模型及其配置保存到指定的目录，方便后续通过 <strong>from_pretrained</strong> 方法重新加载。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 如果 self.model 类型属于支持的类，直接调用 save_pretrained() 保存模型，包括 state_dict 和 safe_serialization 参数。</span><br>        <span class="hljs-keyword">else</span>:<br>            self.model.save_pretrained(<br>                output_dir, <span class="hljs-attribute">state_dict</span>=state_dict, <span class="hljs-attribute">safe_serialization</span>=self.args.save_safetensors<br>            )<br></code></pre></td></tr></table></figure><h3 id="输入参数"><a href="#输入参数" class="headerlink" title="输入参数"></a>输入参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_pretrained</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        save_directory: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, os.PathLike],</span><br><span class="hljs-params">        is_main_process: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        state_dict: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">dict</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 用于保存模型的函数，默认为 torch.save。</span></span><br><span class="hljs-params">        save_function: <span class="hljs-type">Callable</span> = torch.save,</span><br><span class="hljs-params">        push_to_hub: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 每个模型检查点的最大大小，超过该大小时将进行分片保存。</span></span><br><span class="hljs-params">        max_shard_size: <span class="hljs-type">Union</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&quot;5GB&quot;</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 使用 safetensors进行序列化</span></span><br><span class="hljs-params">        safe_serialization: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        variant: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        token: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">bool</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 是否将适配器权重（如果存在）以兼容 PEFT 库的格式保存</span></span><br><span class="hljs-params">        save_peft_format: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        **kwargs,</span><br><span class="hljs-params">    </span>):<br></code></pre></td></tr></table></figure><h3 id="offload-的模块进行特殊处理"><a href="#offload-的模块进行特殊处理" class="headerlink" title="offload 的模块进行特殊处理"></a>offload 的模块进行特殊处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># for offloaded modules</span><br>       module_map = &#123;&#125;<br><br>       <span class="hljs-comment"># Save the model</span><br>       <span class="hljs-keyword">if</span> state_dict <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>           <span class="hljs-comment"># if any model parameters are offloaded, make module map</span><br>           <span class="hljs-keyword">if</span> (<br>               <span class="hljs-comment"># 检查模型是否有设备映射属性</span><br>               <span class="hljs-built_in">hasattr</span>(<span class="hljs-variable language_">self</span>, <span class="hljs-string">&quot;hf_device_map&quot;</span>) <br>               <span class="hljs-comment"># 确认设备映射到多个设备</span><br>               <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(<span class="hljs-variable language_">self</span>.hf_device_map.values())) &gt; <span class="hljs-number">1</span><br>               <span class="hljs-comment"># 判断是否有部分模型参数被 offload（存储到 CPU 或磁盘）。</span><br>               <span class="hljs-keyword">and</span> (<span class="hljs-string">&quot;cpu&quot;</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.hf_device_map.values() <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;disk&quot;</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.hf_device_map.values())<br>           ):<br>           <span class="hljs-comment"># 发出警告，提示用户 CPU 的空闲内存需要大于 shard_size（默认值为 5GB）。</span><br>               warnings.warn(<br>                   <span class="hljs-string">&quot;Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)&quot;</span><br>               )<br><br>               <span class="hljs-comment"># 遍历 model_to_save 的所有子模块。named_modules() 方法返回所有模块的名字和模块本身。准备为每个模块提取参数字典（state_dict）。</span><br>               <span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> model_to_save.named_modules():<br>                   <span class="hljs-keyword">if</span> name == <span class="hljs-string">&quot;&quot;</span>:<br>                       <span class="hljs-keyword">continue</span><br>                   <span class="hljs-comment"># 获取当前模块的参数字典（state_dict）。</span><br>                   module_state_dict = module.state_dict()<br>                   <span class="hljs-comment"># 将模块名和参数名组合，记录到 module_map 中。为每个参数生成唯一的键名：模块名.参数名。在 module_map 中记录键名和模块的对应关系，用于后续加载这些参数。</span><br>                   <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> module_state_dict:<br>                       module_map[name + <span class="hljs-string">f&quot;.<span class="hljs-subst">&#123;key&#125;</span>&quot;</span>] = module<br><br>           <span class="hljs-comment"># 调用 model_to_save 的 state_dict() 方法生成完整的模型参数字典。</span><br>           state_dict = model_to_save.state_dict()<br></code></pre></td></tr></table></figure><p><strong>这部分代码的核心功能是为保存模型时支持 offload 的模块进行特殊处理</strong>：</p><ol><li>检查模型是否包含 offload 到 CPU 或磁盘的参数。</li><li>如果存在 offload 参数，创建 module_map，记录参数与模块的对应关系。</li><li>最后生成完整的 state_dict，用于保存模型。</li></ol><h3 id="分片保存"><a href="#分片保存" class="headerlink" title="分片保存"></a>分片保存</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># Save the model</span><br>       filename_to_tensors = state_dict_split.filename_to_tensors.items()<br>       if module_map:<br>           filename_to_tensors = logging.tqdm(filename_to_tensors, desc=<span class="hljs-string">&quot;Saving checkpoint shards&quot;</span>)<br>       for <span class="hljs-keyword">shard_file, </span>tensors in filename_to_tensors:<br>           <span class="hljs-keyword">shard </span>= &#123;tensor: state_dict[tensor] for tensor in tensors&#125;<br>           <span class="hljs-comment"># remake shard with onloaded parameters if necessary</span><br>           if module_map:<br>               if accelerate_version &lt; version.parse(<span class="hljs-string">&quot;0.31&quot;</span>):<br>                   raise ImportError(<br>                       f<span class="hljs-string">&quot;You need accelerate version to be greater or equal than 0.31 to save models with offloaded parameters. Detected version &#123;accelerate_version&#125;. &quot;</span><br>                       f<span class="hljs-string">&quot;Please upgrade accelerate with `pip install -U accelerate`&quot;</span><br>                   )<br>               <span class="hljs-comment"># init state_dict for this shard</span><br>               <span class="hljs-keyword">shard_state_dict </span>= &#123;name: <span class="hljs-string">&quot;&quot;</span> for name in <span class="hljs-keyword">shard&#125;</span><br><span class="hljs-keyword"></span>               for module_name in <span class="hljs-keyword">shard:</span><br><span class="hljs-keyword"></span>                   module = module_map[module_name]<br>                   <span class="hljs-comment"># update state dict with onloaded parameters</span><br>                   <span class="hljs-keyword">shard_state_dict </span>= get_state_dict_from_offload(module, module_name, <span class="hljs-keyword">shard_state_dict)</span><br><span class="hljs-keyword"></span><br>               <span class="hljs-comment"># assign shard to be the completed state dict</span><br>               <span class="hljs-keyword">shard </span>= <span class="hljs-keyword">shard_state_dict</span><br><span class="hljs-keyword"></span>               del <span class="hljs-keyword">shard_state_dict</span><br><span class="hljs-keyword"></span>               gc.collect()<br><br>           if safe_serialization:<br>               <span class="hljs-comment"># At some point we will need to deal better with save_function (used for TPU and other distributed</span><br>               <span class="hljs-comment"># joyfulness), but for now this enough.</span><br>               safe_save_file(<span class="hljs-keyword">shard, </span>os.path.<span class="hljs-keyword">join(save_directory, </span><span class="hljs-keyword">shard_file), </span>metadata=&#123;<span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;pt&quot;</span>&#125;)<br><span class="hljs-symbol">           else:</span><br>               save_function(<span class="hljs-keyword">shard, </span>os.path.<span class="hljs-keyword">join(save_directory, </span><span class="hljs-keyword">shard_file))</span><br><span class="hljs-keyword"></span><br></code></pre></td></tr></table></figure><p><strong>代码核心逻辑概述：</strong></p><ul><li>分片处理：将大模型的参数按需分片保存，减少内存占用。</li><li>设备卸载管理：处理可能被分配到不同设备（如 CPU 或磁盘）的参数，从设备或磁盘加载卸载的参数到内存中，确保能够正确重新加载。</li><li>依赖库校验：确保环境中的库版本满足保存的要求（如 Accelerate 库版本）。</li></ul><h3 id="保存配置"><a href="#保存配置" class="headerlink" title="保存配置"></a>保存配置</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment"># Save the config</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-symbol">is_main_process:</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-symbol">_hf_peft_config_loaded:</span><br>                model_to_save.config.save_pretrained(save_directory)<br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.can_generate():<br>                <span class="hljs-comment"># generation config built from the model config + the model config holds generation kwargs -&gt; generate</span><br>                <span class="hljs-comment"># may revert to legacy behavior if the two don&#x27;t match</span><br>                <span class="hljs-keyword">if</span> (<br>                    model_to_save.generation_config._from_model_config<br>                    <span class="hljs-keyword">and</span> model_to_save.config._has_non_default_generation_parameters()<br>                ):<br>                    new_generation_config = <span class="hljs-title class_">GenerationConfig</span>.from_model_config(model_to_save.config)<br>                    <span class="hljs-keyword">if</span> new_generation_config != model_to_save.<span class="hljs-symbol">generation_config:</span><br>                        logger.warning(<br>                            <span class="hljs-string">&quot;Your generation config was originally created from the model config, but the model &quot;</span><br>                            <span class="hljs-string">&quot;config has changed since then. Unless you pass the `generation_config` argument to this &quot;</span><br>                            <span class="hljs-string">&quot;model&#x27;s `generate` calls, they will revert to the legacy behavior where the base &quot;</span><br>                            <span class="hljs-string">&quot;`generate` parameterization is loaded from the model config instead. &quot;</span><br>                            <span class="hljs-string">&quot;To avoid this behavior and this warning, we recommend you to overwrite the generation &quot;</span><br>                            <span class="hljs-string">&quot;config model attribute before calling the model&#x27;s `save_pretrained`, preferably also &quot;</span><br>                            <span class="hljs-string">&quot;removing any generation kwargs from the model config. This warning will be raised to an &quot;</span><br>                            <span class="hljs-string">&quot;exception in v4.41.&quot;</span><br>                        )<br>                model_to_save.generation_config.save_pretrained(save_directory)<br><br></code></pre></td></tr></table></figure><p><strong>总结：</strong></p><ul><li>保存模型配置：如果没有加载 PEFT 配置文件，模型的配置文件会被保存。</li><li>生成配置检查与保存：如果模型支持生成，并且生成配置与模型配置不一致，会生成一个新的生成配置，并保存该配置。如果生成配置发生变化，会发出警告，提醒用户注意生成配置的行为。</li><li>最终，保存模型的<strong>配置文件和生成配置文件</strong>config.json 和 generation_config.json ，以确保模型的完整性和生成能力能够在后续使用中被正确恢复。</li></ul><h1 id="torch-save源码分析"><a href="#torch-save源码分析" class="headerlink" title="torch.save源码分析"></a>torch.save源码分析</h1><p>在大模型训练中checkpoint的存储流程在&#x2F;home&#x2F;dell&#x2F;anaconda3&#x2F;envs&#x2F;llama_factory&#x2F;lib&#x2F;python3.11&#x2F;site-packages&#x2F;deepspeed&#x2F;runtime&#x2F;checkpoint_engine&#x2F;torch_checkpoint_engine.py中，调用<strong>torch.save</strong>(<strong>state_dict, path</strong>)函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, state_dict, path: <span class="hljs-built_in">str</span></span>):<br>        logger.info(<span class="hljs-string">f&quot;[Torch] Saving <span class="hljs-subst">&#123;path&#125;</span>...&quot;</span>)<br>        torch.save(state_dict, path)<br>        logger.info(<span class="hljs-string">f&quot;[Torch] Saved <span class="hljs-subst">&#123;path&#125;</span>.&quot;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><ul><li>Pytorch 保存和加载模型后缀：**.pt 和.pth**<br><strong>作用</strong>：保存一个<strong>序列化</strong>（serialized）的目标到磁盘。<br>函数使用了Python的<strong>pickle程序</strong>用于序列化。模型（models），张量<br>（tensors）和文件夹（dictionaries）都是可以用这个函数保存的目标类型</li></ul><p>在保存用于推理或者继续训练的常规检查点的时候，除了模型的state_dict之外，还必须保存其他参数。保存<strong>优化器</strong>的state_dict也非常重要，因为它包含了模型在训练时候优化器的缓存和参数。</p><h2 id="save-函数的参数列表"><a href="#save-函数的参数列表" class="headerlink" title="save 函数的参数列表"></a>save 函数的参数列表</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs php">def <span class="hljs-title function_ invoke__">save</span>(<br>    <span class="hljs-attr">obj</span>: <span class="hljs-keyword">object</span>,<br>    <span class="hljs-attr">f</span>: FILE_LIKE,<br>    <span class="hljs-attr">pickle_module</span>: Any = pickle,<br>    <span class="hljs-attr">pickle_protocol</span>: <span class="hljs-keyword">int</span> = DEFAULT_PROTOCOL,<br>    <span class="hljs-attr">_use_new_zipfile_serialization</span>: <span class="hljs-keyword">bool</span> = True,<br>    <span class="hljs-attr">_disable_byteorder_record</span>: <span class="hljs-keyword">bool</span> = False<br>) -&gt; None:<br></code></pre></td></tr></table></figure><ul><li><strong>obj</strong>: object: 需要保存的对象（如张量、模型等）。</li><li><strong>f</strong>: FILE_LIKE: 目标文件，必须是一个文件类对象，能够实现 write 和 flush 方法，或者是一个包含文件路径的字符串或 os.PathLike 对象。</li><li><strong>pickle_module</strong>: Any &#x3D; pickle: 序列化时使用的模块，默认是 Python 的 pickle 模块，可以传入其他模块来控制序列化过程。</li><li><strong>pickle_protocol</strong>: int &#x3D; DEFAULT_PROTOCOL: 指定使用的 pickle 协议版本，默认使用 PyTorch 默认的协议。</li><li><strong>_use_new_zipfile_serialization</strong>: bool &#x3D; True: 是否使用新的基于 ZIP 的文件格式进行序列化。默认为 True，表示使用新格式。需要使用旧格式保存，可以将 _use_new_zipfile_serialization&#x3D;False</li><li><strong>_disable_byteorder_record</strong>: bool &#x3D; False:用于控制是否记录字节顺序。</li></ul><h2 id="核心逻辑-1"><a href="#核心逻辑-1" class="headerlink" title="核心逻辑"></a>核心逻辑</h2><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-variable">torch._C._log_api_usage_once</span>(<span class="hljs-string">&quot;torch.save&quot;</span>)<br>    <span class="hljs-function"><span class="hljs-title">_check_dill_version</span>(<span class="hljs-variable">pickle_module</span>)</span><br>    <span class="hljs-function"><span class="hljs-title">_check_save_filelike</span>(<span class="hljs-variable">f</span>)</span><br><br></code></pre></td></tr></table></figure><ul><li><strong>torch._C._log_api_usage_once</strong>(“torch.save”)调用内部 C++ 函数 _log_api_usage_once 记录 torch.save 的 API 使用信息。PyTorch 内部会收集 API 调用的统计数据。</li><li>_<strong>check_dill_version</strong>(pickle_module)验证它的版本是否支持当前 PyTorch 的序列化需求。目的是避免由于模块版本问题导致序列化失败。</li><li>_<strong>check_save_filelike</strong>(f) 验证 f 是否是有效的文件类对象或路径。</li></ul><h3 id="检查是否使用新-ZIP-序列化格式"><a href="#检查是否使用新-ZIP-序列化格式" class="headerlink" title="检查是否使用新 ZIP 序列化格式"></a>检查是否使用新 ZIP 序列化格式</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><br><span class="hljs-keyword">if</span> <span class="hljs-variable">_use_new_zipfile_serialization</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-variable">_open_zipfile_writer</span>(f) as opened_zipfile:<br>        <span class="hljs-variable">_save</span>(obj, opened_zipfile, pickle_module, pickle_protocol, <span class="hljs-variable">_disable_byteorder_record</span>)<br>        return<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-variable">_open_file_like</span>(f, <span class="hljs-string">&#x27;wb&#x27;</span>) as opened_file:<br>        <span class="hljs-variable">_legacy_save</span>(obj, opened_file, pickle_module, pickle_protocol)<br></code></pre></td></tr></table></figure><ul><li>_<strong>open_zipfile_writer</strong>(f): 打开一个 ZIP 文件写入器。 f 是文件路径，则创建对应文件。</li><li>_<strong>save</strong>(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record):实际保存逻辑。将对象 obj 序列化并写入到 ZIP 文件中，使用指定的 pickle_module 和 pickle_protocol。<br>_disable_byteorder_record: 控制是否记录字节顺序，通常与硬件架构有关（如小端序&#x2F;大端序）。默认false。</li></ul><h2 id="def-save实际保存逻辑分析"><a href="#def-save实际保存逻辑分析" class="headerlink" title="def _save实际保存逻辑分析"></a>def _save实际保存逻辑分析</h2><h3 id="初始化数据结构"><a href="#初始化数据结构" class="headerlink" title="初始化数据结构"></a>初始化数据结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_save</span>(<span class="hljs-params">obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record</span>):<br>    serialized_storages = &#123;&#125;<br>    id_map: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>] = &#123;&#125;<br>    storage_dtypes: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, torch.dtype] = &#123;&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>serialized_storages</strong> &#x3D; {}存储所有被序列化的 PyTorch 存储对象（Storage）及其对应的键值对。</li><li><strong>id_map: Dict[int, str]</strong> &#x3D; {}维护<strong>存储对象</strong>的唯一标识映射。<br>键：存储对象的 _cdata 属性（内存地址）。<br>值：存储对象的唯一字符串标识符（str(len(id_map)) 自动生成）。<br>避免多次序列化同一个存储对象。</li><li><strong>storage_dtypes</strong>: Dict[int, torch.dtype] &#x3D; {}记录存储对象的 data_ptr（内存指针）和其数据类型。保证同一内存地址的数据类型一致。</li></ul><p>这部分代码的目的是初始化保存过程中需要追踪的信息结构：</p><ol><li>serialized_storages：记录被序列化的存储对象，便于后续写入 ZIP 文件</li><li>id_map：确保存储对象的唯一标识，用于多次引用时避免重复保存。</li><li>storage_dtypes：确保数据类型一致性，防止跨张量操作引发错误。</li></ol><h3 id="生成存储对象的唯一标识符和元信息流程"><a href="#生成存储对象的唯一标识符和元信息流程" class="headerlink" title="生成存储对象的唯一标识符和元信息流程"></a>生成存储对象的唯一标识符和元信息流程</h3><ul><li>判断对象是否为 PyTorch 存储类型（TypedStorage 或旧版 Storage）。</li><li>为特定对象生成持久化 ID，在序列化过程中标记特殊类型的数据对象。<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">def</span> persistent_id(obj):<br>        <span class="hljs-keyword">if</span> isinstance(obj, torch.storage.<span class="hljs-type">TypedStorage</span>) or torch.is_storage(obj):<br><br>            <span class="hljs-keyword">if</span> isinstance(obj, torch.storage.<span class="hljs-type">TypedStorage</span>):<br>                # <span class="hljs-type">TODO</span>: <span class="hljs-type">Once</span> we decide to break serialization <span class="hljs-type">FC</span>, this <span class="hljs-keyword">case</span><br>                # can be deleted<br>                storage = obj._untyped_storage<br>                storage_d<span class="hljs-keyword">type</span> = obj.dtype<br>                storage_type_str = obj._pickle_storage_type()<br>                storage_<span class="hljs-keyword">type</span> = getattr(torch, storage_type_str)<br>                storage_numel = obj._size()<br><br>            <span class="hljs-keyword">else</span>:<br>                storage = obj<br>                storage_d<span class="hljs-keyword">type</span> = torch.uint8<br>                storage_<span class="hljs-keyword">type</span> = normalize_storage_type(type(obj))<br>                storage_numel = storage.nbytes()<br>                 <br></code></pre></td></tr></table></figure></li><li>处理 TypedStorage 类型（具备类型信息的存储）：</li></ul><ol><li>storage &#x3D; obj._untyped_storage 获取 TypedStorage 的底层非类型化存储（UntypedStorage），TypedStorage 是 Storage 的高级抽象，增加了数据类型信息。</li><li>storage_dtype &#x3D; obj.dtype提取存储对象的数据类型（如 torch.float16）。</li><li>storage_type_str &#x3D; obj._pickle_storage_type() 获取存储对象的类型名称（如 FloatStorage）。通过 getattr 获取对应的类型对象。</li><li>storage_numel &#x3D; obj._size()获取存储对象的元素数量（numel）。</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-keyword">if</span> storage<span class="hljs-selector-class">.data_ptr</span>() != <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> storage<span class="hljs-selector-class">.data_ptr</span>() <span class="hljs-keyword">in</span> storage_dtypes:<br>                    <span class="hljs-keyword">if</span> storage_dtype != storage_dtypes<span class="hljs-selector-attr">[storage.data_ptr()]</span>:<br>                        raise <span class="hljs-built_in">RuntimeError</span>(<br>                            <span class="hljs-string">&#x27;Cannot save multiple tensors or storages that &#x27;</span><br>                            <span class="hljs-string">&#x27;view the same data as different types&#x27;</span>)<br>                <span class="hljs-keyword">else</span>:<br>                    storage_dtypes<span class="hljs-selector-attr">[storage.data_ptr()]</span> = storage_dtype<br><br>            storage_key = id_map<span class="hljs-selector-class">.setdefault</span>(storage._cdata, <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(id_map)))<br>            location = <span class="hljs-built_in">location_tag</span>(storage)<br>            serialized_storages<span class="hljs-selector-attr">[storage_key]</span> = storage<br><br>            return (<span class="hljs-string">&#x27;storage&#x27;</span>,<br>                    storage_type,<br>                    storage_key,<br>                    location,<br>                    storage_numel)<br><br>        return None<br></code></pre></td></tr></table></figure><ul><li>if storage.data_ptr() !&#x3D; 0:检查存储对象的指针（data_ptr）是否非零。data_ptr() 返回存储的底层内存地址。</li><li>storage.data_ptr() in storage_dtypes：检查当前存储对象的内存地址是否已存在于 storage_dtypes 中。如果该存储的内存地址尚未记录，存储其对应的数据类型。</li><li>storage_key &#x3D; id_map.setdefault(storage._cdata, str(len(id_map)))为存储对象分配唯一的键（storage_key）。</li><li>location &#x3D; location_tag(storage)获取存储的设备位置信息（如 cpu 或 cuda:0）。</li><li>serialized_storages[storage_key] &#x3D; storage将存储对象按其键（storage_key）保存到 serialized_storages 字典中。</li><li>生成并返回该存储对象的持久化 ID（元组）。</li><li>如果对象 obj 不是存储对象，则返回 None，表示无需特殊处理。</li></ul><p><strong>总结：</strong></p><ul><li>首先判断对象类型（<strong>TypedStorage 和普通 Storage</strong>），提取存储元信息：数据类型、存储类型、大小等元信息。</li><li>然后检查存储是否已分配内存<strong>storage.data_ptr() !&#x3D; 0</strong>，未分配无需进行类型检查。否则检查存储的 data_ptr() 是否已经存在于 storage_dtypes，if <strong>storage_dtype !&#x3D; storage_dtypes[storage.data_ptr()]<strong>，如果当前存储的 dtype 与之前记录的不一致，抛出一个运行时错误。这确保了同一块内存地址上的存储不能在序列化过程中以不同的数据类型保存。如果该 data_ptr() 尚未记录，将当前存储的 dtype 添加到 storage_dtypes 字典中，方便后续检查。</strong>storage_dtypes[storage.data_ptr()] &#x3D; storage_dtype</strong>。<strong>确保引用相同内存地址的多个存储对象在序列化过程中具有一致的数据类型。</strong></li><li>为当前存储生成或获取一个唯一的 <strong>storage_keystorage_key &#x3D; id_map.setdefault(storage._cdata, str(len(id_map)))</strong></li><li>最后返回持久化标识符，用于后续保存和加载过程中的关联</li></ul><h3 id="对象序列化为二进制数据"><a href="#对象序列化为二进制数据" class="headerlink" title="对象序列化为二进制数据"></a>对象序列化为二进制数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Write the pickle data for `obj`</span><br>   data_buf = io.BytesIO()<br>   pickler = pickle_module.Pickler(data_buf, protocol=pickle_protocol)<br>   pickler.persistent_id = persistent_id<br>   pickler.dump(obj)<br>   data_value = data_buf.getvalue()<br>   zip_file.write_record(<span class="hljs-string">&#x27;data.pkl&#x27;</span>, data_value, <span class="hljs-built_in">len</span>(data_value))<br><br>   <span class="hljs-comment"># Write byte order marker</span><br>   <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> _disable_byteorder_record:<br>       <span class="hljs-keyword">if</span> sys.byteorder <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;little&#x27;</span>, <span class="hljs-string">&#x27;big&#x27;</span>]:<br>           <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unknown endianness type: &#x27;</span> + sys.byteorder)<br><br>       zip_file.write_record(<span class="hljs-string">&#x27;byteorder&#x27;</span>, sys.byteorder, <span class="hljs-built_in">len</span>(sys.byteorder))<br></code></pre></td></tr></table></figure><ul><li><strong>data_buf &#x3D; io.BytesIO</strong>() 创建一个内存中的二进制数据缓冲区（BytesIO 对象），存在于内存中，用于存储后续序列化生成的数据。</li><li>创建一个 <strong>Pickler</strong> 对象，用于将 obj 序列化为二进制数据。<strong>pickle_protocol</strong>: 序列化使用的协议版本。</li><li><strong>pickler.persistent_id &#x3D; persistent_id</strong>将 persistent_id 函数分配给 pickler 对象，用于处理序列化中的持久性对象。</li><li><strong>pickler.dump</strong>(obj)使用 Pickler 对象将 obj 序列化为二进制数据，并写入 data_buf 中。<strong>dump</strong> 方法是 Pickler 提供的序列化操作。</li><li><strong>data_value &#x3D; data_buf.getvalue</strong>()从 data_buf 中提取已经序列化的二进制数据，存储到变量 <strong>data_value</strong> 中。</li><li><strong>zip_file.write_record</strong>(‘<strong>data.pkl’, data_value, len(data_value</strong>))将序列化的二进制数据 data_value 写入到 zip_file 中，文件名为 ‘data.pkl’。</li><li>检查是否需要禁用字节序标记写入功能，<strong>sys.byteorder</strong>: 系统的字节序，可以是 ‘little’（小端序）或 ‘big’（大端序）。如果检测到未知字节序，则抛出异常。</li><li><strong>zip_file.write_record(‘byteorder’, sys.byteorder, len(sys.byteorder</strong>))将系统的字节序（sys.byteorder）作为记录写入 zip_file，文件名为 ‘byteorder’。数据内容是 ‘little’ 或 ‘big’。</li></ul><h3 id="张量存储器的保存"><a href="#张量存储器的保存" class="headerlink" title="张量存储器的保存"></a>张量存储器的保存</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># <span class="hljs-keyword">Write</span> <span class="hljs-keyword">each</span> tensor <span class="hljs-keyword">to</span> a file named tensor/the_tensor_key <span class="hljs-keyword">in</span> the zip archive<br>   <span class="hljs-keyword">for key</span> <span class="hljs-keyword">in</span> sorted(serialized_storages.keys()):<br>       <span class="hljs-type">name</span> = f<span class="hljs-string">&#x27;data/&#123;key&#125;&#x27;</span><br>       storage = serialized_storages[key]<br>       # given that we <span class="hljs-keyword">copy</span> things around anyway, we might use <span class="hljs-keyword">storage</span>.cpu()<br>       # this means <span class="hljs-keyword">to</span> that <span class="hljs-keyword">to</span> <span class="hljs-keyword">get</span> tensors serialized, you need <span class="hljs-keyword">to</span> implement<br>       # .cpu() <span class="hljs-keyword">on</span> the underlying <span class="hljs-keyword">Storage</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">storage</span>.device.<span class="hljs-keyword">type</span> != <span class="hljs-string">&#x27;cpu&#x27;</span>:<br>           storage = <span class="hljs-keyword">storage</span>.cpu()<br>       # Now that it <span class="hljs-keyword">is</span> <span class="hljs-keyword">on</span> the CPU we can directly <span class="hljs-keyword">copy</span> it <span class="hljs-keyword">into</span> the zip file<br>       num_bytes = <span class="hljs-keyword">storage</span>.nbytes()<br>       zip_file.write_record(<span class="hljs-type">name</span>, <span class="hljs-keyword">storage</span>, num_bytes)<br></code></pre></td></tr></table></figure><ul><li>遍历 <strong>serialized_storages</strong> 的所有键，并按字母顺序排序，serialized_storages: 一个字典，其中键是张量的名称或标识符，值是对应的存储对象（通常为张量的底层数据）。</li><li>**name &#x3D; f’data&#x2F;{key}’**，生成该键对应的文件路径，存储为变量 name，文件路径以 ‘data&#x2F;‘ 为前缀，再加上键值 key。</li><li><strong>storage &#x3D; serialized_storages[key]</strong> serialized_storages 字典中获取当前键 key 对应的存储对象，赋值给变量 storage。</li><li><strong>if storage.device.type !&#x3D; ‘cpu’</strong>:检查当前存储对象是否位于非 CPU 设备上（如 GPU）。 <strong>storage &#x3D; storage.cpu</strong>()如果设备类型不是 ‘cpu’，则将存储对象移至 CPU。</li><li><strong>num_bytes &#x3D; storage.nbytes</strong>()获取当前存储对象占用的字节数，赋值给变量 num_bytes。</li><li>**zip_file.write_record(name, storage, num_bytes)**将存储对象 <strong>storage</strong> 写入压缩文件中，文件名为 name。<br><strong>name</strong>: 文件路径（如 ‘data&#x2F;weight’）。<br><strong>storage</strong>: 需要写入的数据内容。<br><strong>num_bytes</strong>: 数据的字节大小，用于告知写入函数内假设是一个自定义方法，负责将数据写入到压缩文件中。</li></ul><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><ol><li><strong>对象序列化（Pickle）并存储</strong>：使用 pickle 序列化模块将指定的对象 obj 转换为二进制数据。序列化后的数据被存储在内存缓冲区中，并写入压缩文件 zip_file，文件名为 ‘data.pkl’。</li><li><strong>记录字节序（Byte Order Marker</strong>）：检查系统的字节序（sys.byteorder），确保它是有效的（’little’ 或 ‘big’）。将字节序信息写入压缩文件中，文件名为 ‘byteorder’。</li><li><strong>张量数据的存储</strong>：遍历所有张量存储（serialized_storages 字典中的键值对）。为每个张量生成文件路径，存储为 ‘data&#x2F;<tensor_key>‘。<br>如果张量数据不在 CPU 上（如位于 GPU 上），将其移动到 CPU，确保数据可以被序列化并存储。获取张量数据的字节大小，并将其内容写入压缩文件中。</li></ol><h2 id="def-save函数核心逻辑"><a href="#def-save函数核心逻辑" class="headerlink" title="def_save函数核心逻辑"></a>def_save函数核心逻辑</h2><p>这段代码提供了一个通用的机制，用于将复杂对象和张量序列化并存储在压缩文件中</p><ol><li><strong>初始化数据结构</strong>：</li></ol><ul><li>定义 serialized_storages 用于存储序列化后的张量存储器。</li><li>使用 id_map 记录每个存储器的唯一标识符，避免重复序列化相同数据。</li><li>通过 storage_dtypes 确保多个存储器（storages）共享同一底层数据时，它们的数据类型（dtype）一致</li></ul><ol start="2"><li><strong>生成存储对象的唯一标识符和元信息</strong>：</li></ol><ul><li>该方法处理张量的存储器序列化逻辑，并返回一个包含存储器元数据的标识符（tuple）。</li><li>记录存储器的类型、唯一键、位置（设备）、元素数量等信息。</li><li>检查共享数据指针的存储器是否具有相同的数据类型，确保数据一致性。<br>将存储器添加到 serialized_storages 中，并通过 id_map 分配唯一键名。</li></ul><ol start="3"><li><strong>对象序列化和保存：</strong></li></ol><ul><li>使用 pickle 模块将对象（obj）序列化为二进制数据。</li><li>通过 pickle_module.Pickler 实现自定义序列化行为，并将persistent_id 用于处理张量存储器的特殊序列化需求。</li><li>将序列化后的对象数据写入压缩文件，文件名为 data.pkl。<br>4.<strong>存储字节序（Byte Order Marker）：</strong></li><li>检查系统的字节序（sys.byteorder），确保数据可以跨平台读取。将字节序信息写入压缩文件，文件名为 byteorder。</li></ul><ol start="5"><li><strong>张量存储器的保存：</strong></li></ol><ul><li>遍历 serialized_storages 中的所有张量存储器。如果存储器不在 CPU 上，则将其移动到 CPU。</li><li>获取存储器的字节大小并将其内容写入压缩文件，路径为 data&#x2F;<storage_key>。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Llama_factory</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
