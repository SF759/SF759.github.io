<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>post</title>
    <link href="/2024/11/27/%E6%A3%80%E6%9F%A5%E7%82%B9%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/"/>
    <url>/2024/11/27/%E6%A3%80%E6%9F%A5%E7%82%B9%E5%AD%98%E5%82%A8%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="保存checkpoint日志解析"><a href="#保存checkpoint日志解析" class="headerlink" title="保存checkpoint日志解析"></a>保存checkpoint日志解析</h1><ul><li><strong>保存检查点开始</strong><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">402</span> &gt;&gt; Saving model <span class="hljs-keyword">checkpoint</span> <span class="hljs-keyword">to</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span><br></code></pre></td></tr></table></figure>模型检查点将被保存到指定路径 &#x2F;home&#x2F;dell&#x2F;sdb&#x2F;saves&#x2F;Qwen2-0___5B-Instruct&#x2F;freeze&#x2F;sft&#x2F;checkpoint-25，代表训练中的第25次迭代或某个训练进度标志。</li><li>保存配置文件<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|configuration_utils.py:<span class="hljs-number">472</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">406</span> &gt;&gt; <span class="hljs-keyword">Configuration</span> saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/config.json<br>[<span class="hljs-keyword">INFO</span>|configuration_utils.py:<span class="hljs-number">807</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">18</span>:<span class="hljs-number">54</span>,<span class="hljs-number">406</span> &gt;&gt; <span class="hljs-keyword">Configuration</span> saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/generation_config.json<br></code></pre></td></tr></table></figure>config.json 和 generation_config.json 分别保存模型的基础配置和生成参数配置，确保模型加载时可以正确重现训练环境。</li><li>保存模型权重文件</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|modeling_utils.py:<span class="hljs-number">2766</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">213</span> &gt;&gt; Model weights saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/model.safetensors<br></code></pre></td></tr></table></figure><p>权重文件保存为 model.safetensors 格式。</p><ul><li>保存分词器文件</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-keyword">INFO</span>|tokenization_utils_base.py:<span class="hljs-number">2702</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">214</span> &gt;&gt; tokenizer config file saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/tokenizer_config.json<br>[<span class="hljs-keyword">INFO</span>|tokenization_utils_base.py:<span class="hljs-number">2711</span>] <span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:<span class="hljs-number">00</span>,<span class="hljs-number">214</span> &gt;&gt; Special tokens file saved <span class="hljs-keyword">in</span> /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/special_tokens_map.json<br></code></pre></td></tr></table></figure><p>tokenizer_config.json：分词器的配置信息。<br>special_tokens_map.json：保存特殊 token（如 pad_token、cls_token 等）的映射关系。</p><h2 id="保存-DeepSpeed-检查点"><a href="#保存-DeepSpeed-检查点" class="headerlink" title="保存 DeepSpeed 检查点"></a>保存 DeepSpeed 检查点</h2><ul><li>记录全局步骤的检查点信息</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">20</span>:<span class="hljs-number">31</span>,<span class="hljs-number">627</span>] [<span class="hljs-keyword">INFO</span>] [logging.py:<span class="hljs-number">96</span>:log_dist] [Rank <span class="hljs-number">0</span>] [Torch] <span class="hljs-keyword">Checkpoint</span> global_step25 <span class="hljs-keyword">is</span> about <span class="hljs-keyword">to</span> be saved!<br><br></code></pre></td></tr></table></figure><p>global_step25 代表训练到第 25 个全局步骤的状态。</p><ul><li>保存零冗余优化器的检查点文件<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">22</span>:<span class="hljs-number">33</span>,<span class="hljs-number">574</span>] [<span class="hljs-keyword">INFO</span>] [logging.py:<span class="hljs-number">96</span>:log_dist] [Rank <span class="hljs-number">0</span>] Saving model <span class="hljs-keyword">checkpoint</span>: /home/dell/sdb/saves/Qwen2<span class="hljs-number">-0</span>___5B-Instruct/<span class="hljs-keyword">freeze</span>/sft/<span class="hljs-keyword">checkpoint</span><span class="hljs-number">-25</span>/global_step25/zero_pp_rank_0_mp_rank_00_model_states.pt<br></code></pre></td></tr></table></figure>zero_pp_rank_0_mp_rank_00_model_states.pt：保存当前模型状态，用于零冗余优化（ZeRO）的分布式训练。</li></ul><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">22</span>:<span class="hljs-number">33</span>,<span class="hljs-number">575</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">21</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saving</span> ...<br>[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">26</span>:<span class="hljs-number">56</span>,<span class="hljs-number">161</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">23</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saved</span> ...<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<span class="hljs-number">2024</span><span class="hljs-number">-11</span><span class="hljs-number">-21</span> <span class="hljs-number">10</span>:<span class="hljs-number">27</span>:<span class="hljs-number">11</span>,<span class="hljs-number">351</span>] [<span class="hljs-symbol">INFO</span>] [torch_checkpoint_engine.py:<span class="hljs-number">23</span>:save] [<span class="hljs-symbol">Torch</span>] <span class="hljs-symbol">Saved</span> .../zero_pp_rank_0_mp_rank_00_optim_states.pt.<br></code></pre></td></tr></table></figure><p>zero_pp_rank_0_mp_rank_00_optim_states.pt 保存优化器状态，保证恢复训练时可以正确加载优化器的参数。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7"><span class="hljs-comment">[2024-11-21 10:27:11,369]</span> <span class="hljs-comment">[INFO]</span> <span class="hljs-comment">[engine.py:3589:_save_zero_checkpoint]</span> zero checkpoint saved ...<br><span class="hljs-comment">[2024-11-21 10:27:11,369]</span> <span class="hljs-comment">[INFO]</span> <span class="hljs-comment">[torch_checkpoint_engine.py:33:commit]</span> <span class="hljs-comment">[Torch]</span> Checkpoint global_step25 <span class="hljs-keyword">is</span> ready now!<br><br></code></pre></td></tr></table></figure><p>所有文件均保存完成，检查点 global_step25 可以正常使用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>DeepSpeed 和 PyTorch 结合使用，完整的检查点保存流程</strong>：</p><ol><li>模型参数（权重）</li><li>优化器状态</li><li>配置文件</li><li>特殊辅助文件（如冻结参数形状和分词器信息）</li></ol><h1 id="transformers-trainer-py"><a href="#transformers-trainer-py" class="headerlink" title="transformers&#x2F;trainer.py"></a>transformers&#x2F;trainer.py</h1><h2 id="核心逻辑"><a href="#核心逻辑" class="headerlink" title="核心逻辑"></a>核心逻辑</h2><p>在分布式训练中，多个进程通常会并行运行，为了避免重复保存检查点（例如由每个进程都保存一次），通常只有主进程（通常称为 rank 0 或“进程 0”）负责保存检查点。<br>如果该函数运行到了这一步，说明调用者已经确保此代码只会在进程 0 上执行。因此，无需在此处再次检查是否为主进程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_save</span>(<span class="hljs-params">self, output_dir: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>, state_dict=<span class="hljs-literal">None</span></span>):<br>       output_dir = output_dir <span class="hljs-keyword">if</span> output_dir <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-variable language_">self</span>.args.output_dir<br>       os.makedirs(output_dir, exist_ok=<span class="hljs-literal">True</span>)<br>       logger.info(<span class="hljs-string">f&quot;Saving model checkpoint to <span class="hljs-subst">&#123;output_dir&#125;</span>&quot;</span>)<br>       <span class="hljs-comment"># 确定支持的模型类型</span><br>       supported_classes = (PreTrainedModel,) <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> is_peft_available() <span class="hljs-keyword">else</span> (PreTrainedModel, PeftModel)<br><br>       <span class="hljs-comment"># 模型不是支持的类型,state_dict：获取模型参数的状态字典，用于保存权重。</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-variable language_">self</span>.model, supported_classes):<br>           <span class="hljs-keyword">if</span> state_dict <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>               state_dict = <span class="hljs-variable language_">self</span>.model.state_dict()<br>       <span class="hljs-comment"># 如果通过 self.accelerator.unwrap_model 解包后的模型属于支持的类：调用 save_pretrained() 方法保存模型到 output_dir，并传入 state_dict 和 safe_serialization 参数。</span><br>           <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-variable language_">self</span>.accelerator.unwrap_model(<span class="hljs-variable language_">self</span>.model), supported_classes):<br>               <span class="hljs-variable language_">self</span>.accelerator.unwrap_model(<span class="hljs-variable language_">self</span>.model).save_pretrained(<br>                   output_dir, state_dict=state_dict, safe_serialization=<span class="hljs-variable language_">self</span>.args.save_safetensors<br>               )<br>            <span class="hljs-comment"># 如果解包后的模型仍然不属于支持的类：记录日志：只保存模型state_dict</span><br>           <span class="hljs-keyword">else</span>:<br>               logger.info(<span class="hljs-string">&quot;Trainer.model is not a `PreTrainedModel`, only saving its state dict.&quot;</span>)<br>               <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.args.save_safetensors:<br>                   safetensors.torch.save_file(<br>                       state_dict, os.path.join(output_dir, SAFE_WEIGHTS_NAME), metadata=&#123;<span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;pt&quot;</span>&#125;<br>                   )<br>               <span class="hljs-keyword">else</span>:<br>                   torch.save(state_dict, os.path.join(output_dir, WEIGHTS_NAME))<br>       <span class="hljs-comment"># 如果 self.model 类型属于支持的类，直接调用 save_pretrained() 保存模型，包括 state_dict 和 safe_serialization 参数。</span><br>       <span class="hljs-keyword">else</span>:<br>           <span class="hljs-variable language_">self</span>.model.save_pretrained(<br>               output_dir, state_dict=state_dict, safe_serialization=<span class="hljs-variable language_">self</span>.args.save_safetensors<br>           )<br>       <span class="hljs-comment">#save_pretrained 是主函数，用于保存分词器的完整状态 </span><br>       <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.tokenizer <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>           <span class="hljs-variable language_">self</span>.tokenizer.save_pretrained(output_dir)<br><br>       <span class="hljs-comment"># 训练参数</span><br>       torch.save(<span class="hljs-variable language_">self</span>.args, os.path.join(output_dir, TRAINING_ARGS_NAME))<br></code></pre></td></tr></table></figure><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><strong>这段代码的功能是保存训练过程中生成的检查点，包括</strong>：</p><ul><li>模型权重state_dict：获取模型参数的状态字典，用于保存权重。</li><li>模型及其配置保存到指定的目录：self.model.save_pretrained(只有主进程才会保存模型)</li><li>分词器配置：self.tokenizer.save_pretrained(output_dir)，用于保存模型的函数，默认为 torch.save</li><li>训练参数：torch.save</li></ul><h2 id="save-pretrained核心逻辑"><a href="#save-pretrained核心逻辑" class="headerlink" title="save_pretrained核心逻辑"></a>save_pretrained核心逻辑</h2><p><strong>save_pretrained</strong> 函数的核心逻辑是将训练好的模型及其配置保存到指定的目录，方便后续通过 <strong>from_pretrained</strong> 方法重新加载。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 如果 self.model 类型属于支持的类，直接调用 save_pretrained() 保存模型，包括 state_dict 和 safe_serialization 参数。</span><br>        <span class="hljs-keyword">else</span>:<br>            self.model.save_pretrained(<br>                output_dir, <span class="hljs-attribute">state_dict</span>=state_dict, <span class="hljs-attribute">safe_serialization</span>=self.args.save_safetensors<br>            )<br></code></pre></td></tr></table></figure><h3 id="输入参数"><a href="#输入参数" class="headerlink" title="输入参数"></a>输入参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_pretrained</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        save_directory: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, os.PathLike],</span><br><span class="hljs-params">        is_main_process: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        state_dict: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">dict</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 用于保存模型的函数，默认为 torch.save。</span></span><br><span class="hljs-params">        save_function: <span class="hljs-type">Callable</span> = torch.save,</span><br><span class="hljs-params">        push_to_hub: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 每个模型检查点的最大大小，超过该大小时将进行分片保存。</span></span><br><span class="hljs-params">        max_shard_size: <span class="hljs-type">Union</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&quot;5GB&quot;</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 使用 safetensors进行序列化</span></span><br><span class="hljs-params">        safe_serialization: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        variant: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        token: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">bool</span>]] = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        <span class="hljs-comment"># 是否将适配器权重（如果存在）以兼容 PEFT 库的格式保存</span></span><br><span class="hljs-params">        save_peft_format: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span>,</span><br><span class="hljs-params">        **kwargs,</span><br><span class="hljs-params">    </span>):<br></code></pre></td></tr></table></figure><h3 id="offload-的模块进行特殊处理"><a href="#offload-的模块进行特殊处理" class="headerlink" title="offload 的模块进行特殊处理"></a>offload 的模块进行特殊处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># for offloaded modules</span><br>       module_map = &#123;&#125;<br><br>       <span class="hljs-comment"># Save the model</span><br>       <span class="hljs-keyword">if</span> state_dict <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>           <span class="hljs-comment"># if any model parameters are offloaded, make module map</span><br>           <span class="hljs-keyword">if</span> (<br>               <span class="hljs-comment"># 检查模型是否有设备映射属性</span><br>               <span class="hljs-built_in">hasattr</span>(<span class="hljs-variable language_">self</span>, <span class="hljs-string">&quot;hf_device_map&quot;</span>) <br>               <span class="hljs-comment"># 确认设备映射到多个设备</span><br>               <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(<span class="hljs-variable language_">self</span>.hf_device_map.values())) &gt; <span class="hljs-number">1</span><br>               <span class="hljs-comment"># 判断是否有部分模型参数被 offload（存储到 CPU 或磁盘）。</span><br>               <span class="hljs-keyword">and</span> (<span class="hljs-string">&quot;cpu&quot;</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.hf_device_map.values() <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;disk&quot;</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.hf_device_map.values())<br>           ):<br>           <span class="hljs-comment"># 发出警告，提示用户 CPU 的空闲内存需要大于 shard_size（默认值为 5GB）。</span><br>               warnings.warn(<br>                   <span class="hljs-string">&quot;Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)&quot;</span><br>               )<br><br>               <span class="hljs-comment"># 遍历 model_to_save 的所有子模块。named_modules() 方法返回所有模块的名字和模块本身。准备为每个模块提取参数字典（state_dict）。</span><br>               <span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> model_to_save.named_modules():<br>                   <span class="hljs-keyword">if</span> name == <span class="hljs-string">&quot;&quot;</span>:<br>                       <span class="hljs-keyword">continue</span><br>                   <span class="hljs-comment"># 获取当前模块的参数字典（state_dict）。</span><br>                   module_state_dict = module.state_dict()<br>                   <span class="hljs-comment"># 将模块名和参数名组合，记录到 module_map 中。为每个参数生成唯一的键名：模块名.参数名。在 module_map 中记录键名和模块的对应关系，用于后续加载这些参数。</span><br>                   <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> module_state_dict:<br>                       module_map[name + <span class="hljs-string">f&quot;.<span class="hljs-subst">&#123;key&#125;</span>&quot;</span>] = module<br><br>           <span class="hljs-comment"># 调用 model_to_save 的 state_dict() 方法生成完整的模型参数字典。</span><br>           state_dict = model_to_save.state_dict()<br></code></pre></td></tr></table></figure><p><strong>这部分代码的核心功能是为保存模型时支持 offload 的模块进行特殊处理</strong>：</p><ol><li>检查模型是否包含 offload 到 CPU 或磁盘的参数。</li><li>如果存在 offload 参数，创建 module_map，记录参数与模块的对应关系。</li><li>最后生成完整的 state_dict，用于保存模型。</li></ol><h3 id="分片保存"><a href="#分片保存" class="headerlink" title="分片保存"></a>分片保存</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># Save the model</span><br>       filename_to_tensors = state_dict_split.filename_to_tensors.items()<br>       if module_map:<br>           filename_to_tensors = logging.tqdm(filename_to_tensors, desc=<span class="hljs-string">&quot;Saving checkpoint shards&quot;</span>)<br>       for <span class="hljs-keyword">shard_file, </span>tensors in filename_to_tensors:<br>           <span class="hljs-keyword">shard </span>= &#123;tensor: state_dict[tensor] for tensor in tensors&#125;<br>           <span class="hljs-comment"># remake shard with onloaded parameters if necessary</span><br>           if module_map:<br>               if accelerate_version &lt; version.parse(<span class="hljs-string">&quot;0.31&quot;</span>):<br>                   raise ImportError(<br>                       f<span class="hljs-string">&quot;You need accelerate version to be greater or equal than 0.31 to save models with offloaded parameters. Detected version &#123;accelerate_version&#125;. &quot;</span><br>                       f<span class="hljs-string">&quot;Please upgrade accelerate with `pip install -U accelerate`&quot;</span><br>                   )<br>               <span class="hljs-comment"># init state_dict for this shard</span><br>               <span class="hljs-keyword">shard_state_dict </span>= &#123;name: <span class="hljs-string">&quot;&quot;</span> for name in <span class="hljs-keyword">shard&#125;</span><br><span class="hljs-keyword"></span>               for module_name in <span class="hljs-keyword">shard:</span><br><span class="hljs-keyword"></span>                   module = module_map[module_name]<br>                   <span class="hljs-comment"># update state dict with onloaded parameters</span><br>                   <span class="hljs-keyword">shard_state_dict </span>= get_state_dict_from_offload(module, module_name, <span class="hljs-keyword">shard_state_dict)</span><br><span class="hljs-keyword"></span><br>               <span class="hljs-comment"># assign shard to be the completed state dict</span><br>               <span class="hljs-keyword">shard </span>= <span class="hljs-keyword">shard_state_dict</span><br><span class="hljs-keyword"></span>               del <span class="hljs-keyword">shard_state_dict</span><br><span class="hljs-keyword"></span>               gc.collect()<br><br>           if safe_serialization:<br>               <span class="hljs-comment"># At some point we will need to deal better with save_function (used for TPU and other distributed</span><br>               <span class="hljs-comment"># joyfulness), but for now this enough.</span><br>               safe_save_file(<span class="hljs-keyword">shard, </span>os.path.<span class="hljs-keyword">join(save_directory, </span><span class="hljs-keyword">shard_file), </span>metadata=&#123;<span class="hljs-string">&quot;format&quot;</span>: <span class="hljs-string">&quot;pt&quot;</span>&#125;)<br><span class="hljs-symbol">           else:</span><br>               save_function(<span class="hljs-keyword">shard, </span>os.path.<span class="hljs-keyword">join(save_directory, </span><span class="hljs-keyword">shard_file))</span><br><span class="hljs-keyword"></span><br></code></pre></td></tr></table></figure><p><strong>代码核心逻辑概述：</strong></p><ul><li>分片处理：将大模型的参数按需分片保存，减少内存占用。</li><li>设备卸载管理：处理可能被分配到不同设备（如 CPU 或磁盘）的参数，从设备或磁盘加载卸载的参数到内存中，确保能够正确重新加载。</li><li>依赖库校验：确保环境中的库版本满足保存的要求（如 Accelerate 库版本）。</li></ul><h3 id="保存配置"><a href="#保存配置" class="headerlink" title="保存配置"></a>保存配置</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment"># Save the config</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-symbol">is_main_process:</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-symbol">_hf_peft_config_loaded:</span><br>                model_to_save.config.save_pretrained(save_directory)<br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.can_generate():<br>                <span class="hljs-comment"># generation config built from the model config + the model config holds generation kwargs -&gt; generate</span><br>                <span class="hljs-comment"># may revert to legacy behavior if the two don&#x27;t match</span><br>                <span class="hljs-keyword">if</span> (<br>                    model_to_save.generation_config._from_model_config<br>                    <span class="hljs-keyword">and</span> model_to_save.config._has_non_default_generation_parameters()<br>                ):<br>                    new_generation_config = <span class="hljs-title class_">GenerationConfig</span>.from_model_config(model_to_save.config)<br>                    <span class="hljs-keyword">if</span> new_generation_config != model_to_save.<span class="hljs-symbol">generation_config:</span><br>                        logger.warning(<br>                            <span class="hljs-string">&quot;Your generation config was originally created from the model config, but the model &quot;</span><br>                            <span class="hljs-string">&quot;config has changed since then. Unless you pass the `generation_config` argument to this &quot;</span><br>                            <span class="hljs-string">&quot;model&#x27;s `generate` calls, they will revert to the legacy behavior where the base &quot;</span><br>                            <span class="hljs-string">&quot;`generate` parameterization is loaded from the model config instead. &quot;</span><br>                            <span class="hljs-string">&quot;To avoid this behavior and this warning, we recommend you to overwrite the generation &quot;</span><br>                            <span class="hljs-string">&quot;config model attribute before calling the model&#x27;s `save_pretrained`, preferably also &quot;</span><br>                            <span class="hljs-string">&quot;removing any generation kwargs from the model config. This warning will be raised to an &quot;</span><br>                            <span class="hljs-string">&quot;exception in v4.41.&quot;</span><br>                        )<br>                model_to_save.generation_config.save_pretrained(save_directory)<br><br></code></pre></td></tr></table></figure><p><strong>总结：</strong></p><ul><li>保存模型配置：如果没有加载 PEFT 配置文件，模型的配置文件会被保存。</li><li>生成配置检查与保存：如果模型支持生成，并且生成配置与模型配置不一致，会生成一个新的生成配置，并保存该配置。如果生成配置发生变化，会发出警告，提醒用户注意生成配置的行为。</li><li>最终，保存模型的<strong>配置文件和生成配置文件</strong>config.json 和 generation_config.json ，以确保模型的完整性和生成能力能够在后续使用中被正确恢复。</li></ul><h1 id="torch-save源码分析"><a href="#torch-save源码分析" class="headerlink" title="torch.save源码分析"></a>torch.save源码分析</h1><p>在大模型训练中checkpoint的存储流程在&#x2F;home&#x2F;dell&#x2F;anaconda3&#x2F;envs&#x2F;llama_factory&#x2F;lib&#x2F;python3.11&#x2F;site-packages&#x2F;deepspeed&#x2F;runtime&#x2F;checkpoint_engine&#x2F;torch_checkpoint_engine.py中，调用<strong>torch.save</strong>(<strong>state_dict, path</strong>)函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, state_dict, path: <span class="hljs-built_in">str</span></span>):<br>        logger.info(<span class="hljs-string">f&quot;[Torch] Saving <span class="hljs-subst">&#123;path&#125;</span>...&quot;</span>)<br>        torch.save(state_dict, path)<br>        logger.info(<span class="hljs-string">f&quot;[Torch] Saved <span class="hljs-subst">&#123;path&#125;</span>.&quot;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><ul><li>Pytorch 保存和加载模型后缀：**.pt 和.pth**<br><strong>作用</strong>：保存一个<strong>序列化</strong>（serialized）的目标到磁盘。<br>函数使用了Python的<strong>pickle程序</strong>用于序列化。模型（models），张量<br>（tensors）和文件夹（dictionaries）都是可以用这个函数保存的目标类型</li></ul><p>在保存用于推理或者继续训练的常规检查点的时候，除了模型的state_dict之外，还必须保存其他参数。保存<strong>优化器</strong>的state_dict也非常重要，因为它包含了模型在训练时候优化器的缓存和参数。</p><h2 id="save-函数的参数列表"><a href="#save-函数的参数列表" class="headerlink" title="save 函数的参数列表"></a>save 函数的参数列表</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs php">def <span class="hljs-title function_ invoke__">save</span>(<br>    <span class="hljs-attr">obj</span>: <span class="hljs-keyword">object</span>,<br>    <span class="hljs-attr">f</span>: FILE_LIKE,<br>    <span class="hljs-attr">pickle_module</span>: Any = pickle,<br>    <span class="hljs-attr">pickle_protocol</span>: <span class="hljs-keyword">int</span> = DEFAULT_PROTOCOL,<br>    <span class="hljs-attr">_use_new_zipfile_serialization</span>: <span class="hljs-keyword">bool</span> = True,<br>    <span class="hljs-attr">_disable_byteorder_record</span>: <span class="hljs-keyword">bool</span> = False<br>) -&gt; None:<br></code></pre></td></tr></table></figure><ul><li><strong>obj</strong>: object: 需要保存的对象（如张量、模型等）。</li><li><strong>f</strong>: FILE_LIKE: 目标文件，必须是一个文件类对象，能够实现 write 和 flush 方法，或者是一个包含文件路径的字符串或 os.PathLike 对象。</li><li><strong>pickle_module</strong>: Any &#x3D; pickle: 序列化时使用的模块，默认是 Python 的 pickle 模块，可以传入其他模块来控制序列化过程。</li><li><strong>pickle_protocol</strong>: int &#x3D; DEFAULT_PROTOCOL: 指定使用的 pickle 协议版本，默认使用 PyTorch 默认的协议。</li><li><strong>_use_new_zipfile_serialization</strong>: bool &#x3D; True: 是否使用新的基于 ZIP 的文件格式进行序列化。默认为 True，表示使用新格式。需要使用旧格式保存，可以将 _use_new_zipfile_serialization&#x3D;False</li><li><strong>_disable_byteorder_record</strong>: bool &#x3D; False:用于控制是否记录字节顺序。</li></ul><h2 id="核心逻辑-1"><a href="#核心逻辑-1" class="headerlink" title="核心逻辑"></a>核心逻辑</h2><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-variable">torch._C._log_api_usage_once</span>(<span class="hljs-string">&quot;torch.save&quot;</span>)<br>    <span class="hljs-function"><span class="hljs-title">_check_dill_version</span>(<span class="hljs-variable">pickle_module</span>)</span><br>    <span class="hljs-function"><span class="hljs-title">_check_save_filelike</span>(<span class="hljs-variable">f</span>)</span><br><br></code></pre></td></tr></table></figure><ul><li><strong>torch._C._log_api_usage_once</strong>(“torch.save”)调用内部 C++ 函数 _log_api_usage_once 记录 torch.save 的 API 使用信息。PyTorch 内部会收集 API 调用的统计数据。</li><li>_<strong>check_dill_version</strong>(pickle_module)验证它的版本是否支持当前 PyTorch 的序列化需求。目的是避免由于模块版本问题导致序列化失败。</li><li>_<strong>check_save_filelike</strong>(f) 验证 f 是否是有效的文件类对象或路径。</li></ul><h3 id="检查是否使用新-ZIP-序列化格式"><a href="#检查是否使用新-ZIP-序列化格式" class="headerlink" title="检查是否使用新 ZIP 序列化格式"></a>检查是否使用新 ZIP 序列化格式</h3><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sqf"><br><span class="hljs-keyword">if</span> <span class="hljs-variable">_use_new_zipfile_serialization</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-variable">_open_zipfile_writer</span>(f) as opened_zipfile:<br>        <span class="hljs-variable">_save</span>(obj, opened_zipfile, pickle_module, pickle_protocol, <span class="hljs-variable">_disable_byteorder_record</span>)<br>        return<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">with</span> <span class="hljs-variable">_open_file_like</span>(f, <span class="hljs-string">&#x27;wb&#x27;</span>) as opened_file:<br>        <span class="hljs-variable">_legacy_save</span>(obj, opened_file, pickle_module, pickle_protocol)<br></code></pre></td></tr></table></figure><ul><li>_<strong>open_zipfile_writer</strong>(f): 打开一个 ZIP 文件写入器。 f 是文件路径，则创建对应文件。</li><li>_<strong>save</strong>(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record):实际保存逻辑。将对象 obj 序列化并写入到 ZIP 文件中，使用指定的 pickle_module 和 pickle_protocol。<br>_disable_byteorder_record: 控制是否记录字节顺序，通常与硬件架构有关（如小端序&#x2F;大端序）。默认false。</li></ul><h2 id="def-save实际保存逻辑分析"><a href="#def-save实际保存逻辑分析" class="headerlink" title="def _save实际保存逻辑分析"></a>def _save实际保存逻辑分析</h2><h3 id="初始化数据结构"><a href="#初始化数据结构" class="headerlink" title="初始化数据结构"></a>初始化数据结构</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_save</span>(<span class="hljs-params">obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record</span>):<br>    serialized_storages = &#123;&#125;<br>    id_map: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>] = &#123;&#125;<br>    storage_dtypes: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, torch.dtype] = &#123;&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>serialized_storages</strong> &#x3D; {}存储所有被序列化的 PyTorch 存储对象（Storage）及其对应的键值对。</li><li><strong>id_map: Dict[int, str]</strong> &#x3D; {}维护<strong>存储对象</strong>的唯一标识映射。<br>键：存储对象的 _cdata 属性（内存地址）。<br>值：存储对象的唯一字符串标识符（str(len(id_map)) 自动生成）。<br>避免多次序列化同一个存储对象。</li><li><strong>storage_dtypes</strong>: Dict[int, torch.dtype] &#x3D; {}记录存储对象的 data_ptr（内存指针）和其数据类型。保证同一内存地址的数据类型一致。</li></ul><p>这部分代码的目的是初始化保存过程中需要追踪的信息结构：</p><ol><li>serialized_storages：记录被序列化的存储对象，便于后续写入 ZIP 文件</li><li>id_map：确保存储对象的唯一标识，用于多次引用时避免重复保存。</li><li>storage_dtypes：确保数据类型一致性，防止跨张量操作引发错误。</li></ol><h3 id="生成存储对象的唯一标识符和元信息流程"><a href="#生成存储对象的唯一标识符和元信息流程" class="headerlink" title="生成存储对象的唯一标识符和元信息流程"></a>生成存储对象的唯一标识符和元信息流程</h3><ul><li>判断对象是否为 PyTorch 存储类型（TypedStorage 或旧版 Storage）。</li><li>为特定对象生成持久化 ID，在序列化过程中标记特殊类型的数据对象。<figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">def</span> persistent_id(obj):<br>        <span class="hljs-keyword">if</span> isinstance(obj, torch.storage.<span class="hljs-type">TypedStorage</span>) or torch.is_storage(obj):<br><br>            <span class="hljs-keyword">if</span> isinstance(obj, torch.storage.<span class="hljs-type">TypedStorage</span>):<br>                # <span class="hljs-type">TODO</span>: <span class="hljs-type">Once</span> we decide to break serialization <span class="hljs-type">FC</span>, this <span class="hljs-keyword">case</span><br>                # can be deleted<br>                storage = obj._untyped_storage<br>                storage_d<span class="hljs-keyword">type</span> = obj.dtype<br>                storage_type_str = obj._pickle_storage_type()<br>                storage_<span class="hljs-keyword">type</span> = getattr(torch, storage_type_str)<br>                storage_numel = obj._size()<br><br>            <span class="hljs-keyword">else</span>:<br>                storage = obj<br>                storage_d<span class="hljs-keyword">type</span> = torch.uint8<br>                storage_<span class="hljs-keyword">type</span> = normalize_storage_type(type(obj))<br>                storage_numel = storage.nbytes()<br>                 <br></code></pre></td></tr></table></figure></li><li>处理 TypedStorage 类型（具备类型信息的存储）：</li></ul><ol><li>storage &#x3D; obj._untyped_storage 获取 TypedStorage 的底层非类型化存储（UntypedStorage），TypedStorage 是 Storage 的高级抽象，增加了数据类型信息。</li><li>storage_dtype &#x3D; obj.dtype提取存储对象的数据类型（如 torch.float16）。</li><li>storage_type_str &#x3D; obj._pickle_storage_type() 获取存储对象的类型名称（如 FloatStorage）。通过 getattr 获取对应的类型对象。</li><li>storage_numel &#x3D; obj._size()获取存储对象的元素数量（numel）。</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-keyword">if</span> storage<span class="hljs-selector-class">.data_ptr</span>() != <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">if</span> storage<span class="hljs-selector-class">.data_ptr</span>() <span class="hljs-keyword">in</span> storage_dtypes:<br>                    <span class="hljs-keyword">if</span> storage_dtype != storage_dtypes<span class="hljs-selector-attr">[storage.data_ptr()]</span>:<br>                        raise <span class="hljs-built_in">RuntimeError</span>(<br>                            <span class="hljs-string">&#x27;Cannot save multiple tensors or storages that &#x27;</span><br>                            <span class="hljs-string">&#x27;view the same data as different types&#x27;</span>)<br>                <span class="hljs-keyword">else</span>:<br>                    storage_dtypes<span class="hljs-selector-attr">[storage.data_ptr()]</span> = storage_dtype<br><br>            storage_key = id_map<span class="hljs-selector-class">.setdefault</span>(storage._cdata, <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(id_map)))<br>            location = <span class="hljs-built_in">location_tag</span>(storage)<br>            serialized_storages<span class="hljs-selector-attr">[storage_key]</span> = storage<br><br>            return (<span class="hljs-string">&#x27;storage&#x27;</span>,<br>                    storage_type,<br>                    storage_key,<br>                    location,<br>                    storage_numel)<br><br>        return None<br></code></pre></td></tr></table></figure><ul><li>if storage.data_ptr() !&#x3D; 0:检查存储对象的指针（data_ptr）是否非零。data_ptr() 返回存储的底层内存地址。</li><li>storage.data_ptr() in storage_dtypes：检查当前存储对象的内存地址是否已存在于 storage_dtypes 中。如果该存储的内存地址尚未记录，存储其对应的数据类型。</li><li>storage_key &#x3D; id_map.setdefault(storage._cdata, str(len(id_map)))为存储对象分配唯一的键（storage_key）。</li><li>location &#x3D; location_tag(storage)获取存储的设备位置信息（如 cpu 或 cuda:0）。</li><li>serialized_storages[storage_key] &#x3D; storage将存储对象按其键（storage_key）保存到 serialized_storages 字典中。</li><li>生成并返回该存储对象的持久化 ID（元组）。</li><li>如果对象 obj 不是存储对象，则返回 None，表示无需特殊处理。</li></ul><p><strong>总结：</strong></p><ul><li>首先判断对象类型（<strong>TypedStorage 和普通 Storage</strong>），提取存储元信息：数据类型、存储类型、大小等元信息。</li><li>然后检查存储是否已分配内存<strong>storage.data_ptr() !&#x3D; 0</strong>，未分配无需进行类型检查。否则检查存储的 data_ptr() 是否已经存在于 storage_dtypes，if <strong>storage_dtype !&#x3D; storage_dtypes[storage.data_ptr()]<strong>，如果当前存储的 dtype 与之前记录的不一致，抛出一个运行时错误。这确保了同一块内存地址上的存储不能在序列化过程中以不同的数据类型保存。如果该 data_ptr() 尚未记录，将当前存储的 dtype 添加到 storage_dtypes 字典中，方便后续检查。</strong>storage_dtypes[storage.data_ptr()] &#x3D; storage_dtype</strong>。<strong>确保引用相同内存地址的多个存储对象在序列化过程中具有一致的数据类型。</strong></li><li>为当前存储生成或获取一个唯一的 <strong>storage_keystorage_key &#x3D; id_map.setdefault(storage._cdata, str(len(id_map)))</strong></li><li>最后返回持久化标识符，用于后续保存和加载过程中的关联</li></ul><h3 id="对象序列化为二进制数据"><a href="#对象序列化为二进制数据" class="headerlink" title="对象序列化为二进制数据"></a>对象序列化为二进制数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Write the pickle data for `obj`</span><br>   data_buf = io.BytesIO()<br>   pickler = pickle_module.Pickler(data_buf, protocol=pickle_protocol)<br>   pickler.persistent_id = persistent_id<br>   pickler.dump(obj)<br>   data_value = data_buf.getvalue()<br>   zip_file.write_record(<span class="hljs-string">&#x27;data.pkl&#x27;</span>, data_value, <span class="hljs-built_in">len</span>(data_value))<br><br>   <span class="hljs-comment"># Write byte order marker</span><br>   <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> _disable_byteorder_record:<br>       <span class="hljs-keyword">if</span> sys.byteorder <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;little&#x27;</span>, <span class="hljs-string">&#x27;big&#x27;</span>]:<br>           <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unknown endianness type: &#x27;</span> + sys.byteorder)<br><br>       zip_file.write_record(<span class="hljs-string">&#x27;byteorder&#x27;</span>, sys.byteorder, <span class="hljs-built_in">len</span>(sys.byteorder))<br></code></pre></td></tr></table></figure><ul><li><strong>data_buf &#x3D; io.BytesIO</strong>() 创建一个内存中的二进制数据缓冲区（BytesIO 对象），存在于内存中，用于存储后续序列化生成的数据。</li><li>创建一个 <strong>Pickler</strong> 对象，用于将 obj 序列化为二进制数据。<strong>pickle_protocol</strong>: 序列化使用的协议版本。</li><li><strong>pickler.persistent_id &#x3D; persistent_id</strong>将 persistent_id 函数分配给 pickler 对象，用于处理序列化中的持久性对象。</li><li><strong>pickler.dump</strong>(obj)使用 Pickler 对象将 obj 序列化为二进制数据，并写入 data_buf 中。<strong>dump</strong> 方法是 Pickler 提供的序列化操作。</li><li><strong>data_value &#x3D; data_buf.getvalue</strong>()从 data_buf 中提取已经序列化的二进制数据，存储到变量 <strong>data_value</strong> 中。</li><li><strong>zip_file.write_record</strong>(‘<strong>data.pkl’, data_value, len(data_value</strong>))将序列化的二进制数据 data_value 写入到 zip_file 中，文件名为 ‘data.pkl’。</li><li>检查是否需要禁用字节序标记写入功能，<strong>sys.byteorder</strong>: 系统的字节序，可以是 ‘little’（小端序）或 ‘big’（大端序）。如果检测到未知字节序，则抛出异常。</li><li><strong>zip_file.write_record(‘byteorder’, sys.byteorder, len(sys.byteorder</strong>))将系统的字节序（sys.byteorder）作为记录写入 zip_file，文件名为 ‘byteorder’。数据内容是 ‘little’ 或 ‘big’。</li></ul><h3 id="张量存储器的保存"><a href="#张量存储器的保存" class="headerlink" title="张量存储器的保存"></a>张量存储器的保存</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># <span class="hljs-keyword">Write</span> <span class="hljs-keyword">each</span> tensor <span class="hljs-keyword">to</span> a file named tensor/the_tensor_key <span class="hljs-keyword">in</span> the zip archive<br>   <span class="hljs-keyword">for key</span> <span class="hljs-keyword">in</span> sorted(serialized_storages.keys()):<br>       <span class="hljs-type">name</span> = f<span class="hljs-string">&#x27;data/&#123;key&#125;&#x27;</span><br>       storage = serialized_storages[key]<br>       # given that we <span class="hljs-keyword">copy</span> things around anyway, we might use <span class="hljs-keyword">storage</span>.cpu()<br>       # this means <span class="hljs-keyword">to</span> that <span class="hljs-keyword">to</span> <span class="hljs-keyword">get</span> tensors serialized, you need <span class="hljs-keyword">to</span> implement<br>       # .cpu() <span class="hljs-keyword">on</span> the underlying <span class="hljs-keyword">Storage</span><br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">storage</span>.device.<span class="hljs-keyword">type</span> != <span class="hljs-string">&#x27;cpu&#x27;</span>:<br>           storage = <span class="hljs-keyword">storage</span>.cpu()<br>       # Now that it <span class="hljs-keyword">is</span> <span class="hljs-keyword">on</span> the CPU we can directly <span class="hljs-keyword">copy</span> it <span class="hljs-keyword">into</span> the zip file<br>       num_bytes = <span class="hljs-keyword">storage</span>.nbytes()<br>       zip_file.write_record(<span class="hljs-type">name</span>, <span class="hljs-keyword">storage</span>, num_bytes)<br></code></pre></td></tr></table></figure><ul><li>遍历 <strong>serialized_storages</strong> 的所有键，并按字母顺序排序，serialized_storages: 一个字典，其中键是张量的名称或标识符，值是对应的存储对象（通常为张量的底层数据）。</li><li>**name &#x3D; f’data&#x2F;{key}’**，生成该键对应的文件路径，存储为变量 name，文件路径以 ‘data&#x2F;‘ 为前缀，再加上键值 key。</li><li><strong>storage &#x3D; serialized_storages[key]</strong> serialized_storages 字典中获取当前键 key 对应的存储对象，赋值给变量 storage。</li><li><strong>if storage.device.type !&#x3D; ‘cpu’</strong>:检查当前存储对象是否位于非 CPU 设备上（如 GPU）。 <strong>storage &#x3D; storage.cpu</strong>()如果设备类型不是 ‘cpu’，则将存储对象移至 CPU。</li><li><strong>num_bytes &#x3D; storage.nbytes</strong>()获取当前存储对象占用的字节数，赋值给变量 num_bytes。</li><li>**zip_file.write_record(name, storage, num_bytes)**将存储对象 <strong>storage</strong> 写入压缩文件中，文件名为 name。<br><strong>name</strong>: 文件路径（如 ‘data&#x2F;weight’）。<br><strong>storage</strong>: 需要写入的数据内容。<br><strong>num_bytes</strong>: 数据的字节大小，用于告知写入函数内假设是一个自定义方法，负责将数据写入到压缩文件中。</li></ul><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><ol><li><strong>对象序列化（Pickle）并存储</strong>：使用 pickle 序列化模块将指定的对象 obj 转换为二进制数据。序列化后的数据被存储在内存缓冲区中，并写入压缩文件 zip_file，文件名为 ‘data.pkl’。</li><li><strong>记录字节序（Byte Order Marker</strong>）：检查系统的字节序（sys.byteorder），确保它是有效的（’little’ 或 ‘big’）。将字节序信息写入压缩文件中，文件名为 ‘byteorder’。</li><li><strong>张量数据的存储</strong>：遍历所有张量存储（serialized_storages 字典中的键值对）。为每个张量生成文件路径，存储为 ‘data&#x2F;<tensor_key>‘。<br>如果张量数据不在 CPU 上（如位于 GPU 上），将其移动到 CPU，确保数据可以被序列化并存储。获取张量数据的字节大小，并将其内容写入压缩文件中。</li></ol><h2 id="def-save函数核心逻辑"><a href="#def-save函数核心逻辑" class="headerlink" title="def_save函数核心逻辑"></a>def_save函数核心逻辑</h2><p>这段代码提供了一个通用的机制，用于将复杂对象和张量序列化并存储在压缩文件中</p><ol><li><strong>初始化数据结构</strong>：</li></ol><ul><li>定义 serialized_storages 用于存储序列化后的张量存储器。</li><li>使用 id_map 记录每个存储器的唯一标识符，避免重复序列化相同数据。</li><li>通过 storage_dtypes 确保多个存储器（storages）共享同一底层数据时，它们的数据类型（dtype）一致</li></ul><ol start="2"><li><strong>生成存储对象的唯一标识符和元信息</strong>：</li></ol><ul><li>该方法处理张量的存储器序列化逻辑，并返回一个包含存储器元数据的标识符（tuple）。</li><li>记录存储器的类型、唯一键、位置（设备）、元素数量等信息。</li><li>检查共享数据指针的存储器是否具有相同的数据类型，确保数据一致性。<br>将存储器添加到 serialized_storages 中，并通过 id_map 分配唯一键名。</li></ul><ol start="3"><li><strong>对象序列化和保存：</strong></li></ol><ul><li>使用 pickle 模块将对象（obj）序列化为二进制数据。</li><li>通过 pickle_module.Pickler 实现自定义序列化行为，并将persistent_id 用于处理张量存储器的特殊序列化需求。</li><li>将序列化后的对象数据写入压缩文件，文件名为 data.pkl。<br>4.<strong>存储字节序（Byte Order Marker）：</strong></li><li>检查系统的字节序（sys.byteorder），确保数据可以跨平台读取。将字节序信息写入压缩文件，文件名为 byteorder。</li></ul><ol start="5"><li><strong>张量存储器的保存：</strong></li></ol><ul><li>遍历 serialized_storages 中的所有张量存储器。如果存储器不在 CPU 上，则将其移动到 CPU。</li><li>获取存储器的字节大小并将其内容写入压缩文件，路径为 data&#x2F;<storage_key>。</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/11/26/hello-world/"/>
    <url>/2024/11/26/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
